{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Process\n",
    "\n",
    "Assume the task we want to classify is determining the label $y$ of observed data $X=(x_1, x_2)$, where $x_1, x_2$ are the attributes of $X$. Further, we assume attribute $x_1 \\in A_1 = \\{1, 2, 3\\}$ and attribute $x_2 \\in A_2 = \\{S, M, L\\}$. And the label $y \\in C = \\{1, -1\\}$. The observed data and labels are below.\n",
    "\n",
    "The assumed problem is to predict the data $X = \\{2, S\\}^T$, which is supposed to get estimation value $-1$ based on the Multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_random: \n",
      "[[('2', 'L') '-1']\n",
      " [('3', 'M') '-1']\n",
      " [('1', 'S') '-1']\n",
      " [('2', 'S') '-1']\n",
      " [('1', 'S') '1']\n",
      " [('2', 'M') '-1']\n",
      " [('2', 'S') '-1']\n",
      " [('2', 'M') '1']\n",
      " [('3', 'L') '-1']\n",
      " [('2', 'M') '1']\n",
      " [('1', 'S') '-1']\n",
      " [('1', 'L') '-1']\n",
      " [('1', 'L') '-1']\n",
      " [('3', 'M') '-1']\n",
      " [('2', 'S') '-1']]\n",
      "X_hard_code: \n",
      "[[('1', 'S') '-1']\n",
      " [('1', 'M') '-1']\n",
      " [('1', 'M') '1']\n",
      " [('1', 'S') '1']\n",
      " [('1', 'S') '-1']\n",
      " [('2', 'S') '-1']\n",
      " [('2', 'M') '-1']\n",
      " [('2', 'M') '1']\n",
      " [('2', 'L') '1']\n",
      " [('2', 'L') '1']\n",
      " [('3', 'L') '1']\n",
      " [('3', 'M') '1']\n",
      " [('3', 'M') '1']\n",
      " [('3', 'L') '1']\n",
      " [('3', 'L') '-1']]\n"
     ]
    }
   ],
   "source": [
    "import gen_synthetic as gs\n",
    "\n",
    "# Test the randomly generated data\n",
    "x1_dom = [1, 2, 3]\n",
    "x2_dom = ['S', 'M', 'L']\n",
    "x_dom = np.array([x1_dom, x2_dom])\n",
    "y_dom = np.array([['-1', '1'], ])\n",
    "\n",
    "X_random = gs.gen_naive_bayes_synthetic(x_dom, y_dom, 15)\n",
    "print 'X_random: \\n', X_random\n",
    "\n",
    "# Test embedded hard code data\n",
    "X_hard_code = gs.gen_naive_bayes_synthetic([], [], 0, hard_code=True)\n",
    "print 'X_hard_code: \\n', X_hard_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes without Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1   2\n",
      "2   1  S  -1\n",
      "4   1  S   1\n",
      "10  1  S  -1\n",
      "11  1  L  -1\n",
      "12  1  L  -1\n"
     ]
    }
   ],
   "source": [
    "from classifiers import MultinomialNB\n",
    "mnNB = MultinomialNB()\n",
    "\n",
    "mnNB.train(x_dom, y_dom, X_random)\n",
    "df = mnNB.counts_table\n",
    "print df[df[0] == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1   2\n",
      "0  1  S  -1\n",
      "1  1  M  -1\n",
      "2  1  M   1\n",
      "3  1  S   1\n",
      "4  1  S  -1\n",
      "number of above rows:  5\n",
      "   0  1   2\n",
      "1  1  M  -1\n",
      "2  1  M   1\n",
      "number of above rows:  2\n",
      "number of non-existing rows: 0\n",
      "\n",
      "The probability table is:\n",
      "k = -1, prob = 0.400000\n",
      "k = 1, prob = 0.600000\n",
      "k = 1|-1, prob = 0.500000\n",
      "k = 1|1, prob = 0.222222\n",
      "k = 2|-1, prob = 0.333333\n",
      "k = 2|1, prob = 0.333333\n",
      "k = 3|-1, prob = 0.166667\n",
      "k = 3|1, prob = 0.444444\n",
      "k = L|-1, prob = 0.166667\n",
      "k = L|1, prob = 0.444444\n",
      "k = M|-1, prob = 0.333333\n",
      "k = M|1, prob = 0.444444\n",
      "k = S|-1, prob = 0.500000\n",
      "k = S|1, prob = 0.111111\n"
     ]
    }
   ],
   "source": [
    "mnNB.train(x_dom, y_dom, X_hard_code)\n",
    "df = mnNB.counts_table\n",
    "print df[df[0] == '1']\n",
    "print 'number of above rows: ', len(df[df[0] == '1'])\n",
    "\n",
    "print df[(df[0] == '1') & (df[1] == 'M')]\n",
    "print 'number of above rows: ', len(df[(df[0] == '1') & (df[1] == 'M')])\n",
    "\n",
    "print 'number of non-existing rows:', len(df[df[0] == '7'])\n",
    "\n",
    "print '\\nThe probability table is:'\n",
    "for k in sorted(mnNB.prob_table):\n",
    "    print 'k = %s, prob = %f' % (k, mnNB.prob_table[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1   2\n",
      "0  1  S  -1\n",
      "1  1  M  -1\n",
      "2  1  M   1\n",
      "3  1  S   1\n",
      "4  1  S  -1\n",
      "number of above rows:  5\n",
      "   0  1   2\n",
      "1  1  M  -1\n",
      "2  1  M   1\n",
      "number of above rows:  5\n",
      "number of non-existing rows: 0\n",
      "\n",
      "The probability table is:\n",
      "k = -1, prob = 0.400000\n",
      "k = 1, prob = 0.600000\n",
      "k = 1|-1, prob = 0.444444\n",
      "k = 1|1, prob = 0.250000\n",
      "k = 2|-1, prob = 0.333333\n",
      "k = 2|1, prob = 0.333333\n",
      "k = 3|-1, prob = 0.222222\n",
      "k = 3|1, prob = 0.416667\n",
      "k = L|-1, prob = 0.222222\n",
      "k = L|1, prob = 0.416667\n",
      "k = M|-1, prob = 0.333333\n",
      "k = M|1, prob = 0.416667\n",
      "k = S|-1, prob = 0.444444\n",
      "k = S|1, prob = 0.166667\n"
     ]
    }
   ],
   "source": [
    "mnNB.train(x_dom, y_dom, X_hard_code, laplaceS=1)\n",
    "df = mnNB.counts_table\n",
    "print df[df[0] == '1']\n",
    "print 'number of above rows: ', len(df[df[0] == '1'])\n",
    "\n",
    "print df[(df[0] == '1') & (df[1] == 'M')]\n",
    "print 'number of above rows: ', len(df[df[0] == '1'])\n",
    "\n",
    "print 'number of non-existing rows:', len(df[df[0] == '7'])\n",
    "\n",
    "print '\\nThe probability table is:'\n",
    "for k in sorted(mnNB.prob_table):\n",
    "    print 'k = %s, prob = %f' % (k, mnNB.prob_table[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-1']\n"
     ]
    }
   ],
   "source": [
    "XX_test = ['2', 'S']\n",
    "mnNB.predict(XX_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "As part of this problem, you will implement a Naive Bayes classifier for classifying movie reviews as positive or negative. The dataset that you will be using is the IMDB Large Movie Review dataset (Maas et. al, ACL 2011). The processed dataset can be found [here](https://www.dropbox.com/s/liz0o40f5mpj8ye/hw1_dataset_nb.tar.gz?dl=0). The task is to estimate appropriate parameters using the training data, and use it to predict reviews from the test data, and classify each of them as either positive or negative.\n",
    "\n",
    "We employ the *Multinomial Naive Bayes model for modeling each $P(X_i | Y = y_k)$ ($i = 1 .. n$), with appropriate word counts* (Note $n$ is the number of dimensions).\n",
    "\n",
    "Please use Matlab, Python, R, C/C++ or Java for your implementation. Note that you will have to submit your codes in Autolab, and provide the answers to the questions in the below subsections in your report.\n",
    "\n",
    "### Preprocessing\n",
    "The dataset is partitioned into 2 folders: `train` and `test`, each of which contains 2 subfolders (`pos` and `neg`, for positive and negative samples respectively). The content of each file has to be converted to a bag-of-words representation. So the first task is to go through all the files in the `train` folder, and construct the vocabulary $V$ of all unique words. Please ignore all the stop-words as given in the file `sw.txt` (provided along with the dataset). The words from each file (both in training and testing phase) must be extracted by splitting the raw text only with whitespace characters and {\\color{red}converting them to lowercase characters}. \n",
    "\n",
    "The next step is to get counts of each individual words for the positive and the negative classes separately, to get $P(word | class)$. \n",
    "\n",
    "### Classification\n",
    "In this step, you need to go through all the negative and positive samples in the test data, and classify each sample according to the parameters learned earlier. The classification should be done by comparing the log-posterior (un-normalized), which is given by $\\log(P(X|Y)P(Y))$, for both the classes.\n",
    "\n",
    "### Laplace smoothing\n",
    "An issue with the original Naive Bayes setup is that if a test sample contains a word which is not present in the dictionary, the $P(word|label)$ goes to $0$. To mitigate this issue, one solution is to employ Laplace smoothing (it has a parameter $\\alpha$). Augment your $P(word | class)$ calculations by including the appropriate terms for doing Laplace smoothing. \n",
    "\n",
    "Report the confusion matrix and overall accuracy of your classifier on the test dataset with $\\alpha = 1$. Recall that the confusion matrix for such 2-class classification problem, is a matrix of the number of true positives (positive samples correctly classified as positive), number of true negatives (negative samples correctly classified as negative), number of false positives (negative samples incorrectly classified as positive), and number of false negatives (positive samples incorrectly classified as negative). The accuracy is the ratio of sum of true positives and true negatives, and the total number of samples (in the test dataset).\n",
    "\n",
    "Now vary the value of $\\alpha$ from $0.0001$ to $1000$ (by multiplying $\\alpha$ with 10 each time), and report a plot of the accuracy on the test dataset for the corresponding values of $\\alpha$. (The x-axis should represent $\\alpha$ values and use a $\\log$ scale for the x-axis).\n",
    "\n",
    " Why do you think the accuracy suffers when $\\alpha$ is too high or too low? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story of a man who has unnatural feelings for a pig  Starts out with a opening scene that is a terrific example of absurd comedy  A formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it's singers  Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting  Even those from the era should be turned off  The cryptic dialogue would make Shakespeare seem easy to a third grader  On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond  Future stars Sally Kirkland and Frederic Forrest can be seen briefly \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "fileName = '0_3.txt'\n",
    "dataPath = os.path.join('dataset', 'hw1_dataset_nb', 'train', 'neg', fileName)\n",
    "data = open(dataPath, 'r').read()\n",
    "print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training, testing data and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset import removePunctuation\n",
    "\n",
    "def getData(dir_pre, data_type, cg_list, sw=None):\n",
    "    \"\"\"\n",
    "    Reading data from 'dir_pre'. The data is categories\n",
    "    with name list 'data_type'. And the specified data\n",
    "    type is categoried with name list 'cg_list'. If the\n",
    "    stop words list 'sw' is not empty, the content will\n",
    "    remove the words in 'sw'.\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    - dir_pre  : the prefix of data set's directory.\n",
    "    - data_type: 'train' or 'test'.\n",
    "    - cg_list  : specified data type's category name list.\n",
    "    - sw       : stop words list.\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    A dictionary with key name as cg_list. Here for IMDB data,\n",
    "    it's 'neg' --> 'list of comments list'\n",
    "    \"\"\"\n",
    "    docs = {}\n",
    "    for cg in cg_list:\n",
    "        texts = []\n",
    "        pathPre = os.path.join(dir_pre, data_type, cg)\n",
    "        dir_contents = os.listdir(pathPre)\n",
    "\n",
    "        for fN in dir_contents:\n",
    "            contents = removePunctuation(open(os.path.join(pathPre, fN), 'r').read()).split()\n",
    "            \n",
    "            # Remove stop words.\n",
    "            if not sw is None:\n",
    "                contents = [x for x in contents if not x in sw]\n",
    "            \n",
    "            texts.append(contents)\n",
    "\n",
    "        docs[cg] = texts\n",
    "        \n",
    "    return docs   \n",
    "\n",
    "stop_words = open(os.path.join('dataset', 'hw1_dataset_nb', 'sw.txt'), 'r').read().split()\n",
    "\n",
    "cgList = ['neg', 'pos']\n",
    "dirP = os.path.join('dataset', 'hw1_dataset_nb')\n",
    "X_train = getData(dirP, 'train', cgList, sw=stop_words)\n",
    "X_test = getData(dirP, 'test', cgList, sw=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'across', 'after']\n"
     ]
    }
   ],
   "source": [
    "print stop_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Story', 'unnatural', 'feelings', 'pig', 'Starts', 'scene', 'terrific', 'example', 'absurd', 'comedy', 'A', 'formal', 'orchestra', 'audience', 'insane', 'violent', 'mob', 'crazy', 'chantings', \"it's\", 'singers', 'Unfortunately', 'stays', 'absurd', 'WHOLE', 'time', 'narrative', 'eventually', 'putting', 'Even', 'era', 'The', 'cryptic', 'dialogue', 'Shakespeare', 'easy', 'third', 'grader', 'On', 'technical', 'level', \"it's\", 'cinematography', 'future', 'Vilmos', 'Zsigmond', 'Future', 'stars', 'Sally', 'Kirkland', 'Frederic', 'Forrest', 'seen', 'briefly']\n"
     ]
    }
   ],
   "source": [
    "print X_train['neg'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** training data: ******\n",
      "0 -----------\n",
      "['Story', 'unnatural', 'feelings', 'pig', 'Starts', 'scene', 'terrific', 'example', 'absurd', 'comedy', 'A', 'formal', 'orchestra', 'audience', 'insane', 'violent', 'mob', 'crazy', 'chantings', \"it's\", 'singers', 'Unfortunately', 'stays', 'absurd', 'WHOLE', 'time', 'narrative', 'eventually', 'putting', 'Even', 'era', 'The', 'cryptic', 'dialogue', 'Shakespeare', 'easy', 'third', 'grader', 'On', 'technical', 'level', \"it's\", 'cinematography', 'future', 'Vilmos', 'Zsigmond', 'Future', 'stars', 'Sally', 'Kirkland', 'Frederic', 'Forrest', 'seen', 'briefly']\n",
      "1 -----------\n",
      "['Airport', \"'77\", 'starts', 'brand', 'luxury', '747', 'plane', 'loaded', 'valuable', 'paintings', 'belonging', 'rich', 'businessman', 'Philip', 'Stevens', 'James', 'Stewart', 'flying', 'bunch', \"VIP's\", 'estate', 'preparation', 'public', 'museum', 'board', 'Stevens', 'daughter', 'Julie', 'Kathleen', 'Quinlan', 'son', 'The', 'luxury', 'jetliner', 'takes', 'planned', 'mid-air', 'plane', 'hi-jacked', 'co-pilot', 'Chambers', 'Robert', 'Foxworth', \"accomplice's\", 'Banker', 'Monte', 'Markham', 'Wilson', 'Michael', 'Pataki', 'knock', 'passengers', 'crew', 'sleeping', 'gas', 'plan', 'steal', 'valuable', 'cargo', 'land', 'disused', 'plane', 'strip', 'isolated', 'island', 'descent', 'Chambers', 'hits', 'oil', 'rig', 'Ocean', 'loses', 'control', 'plane', 'sending', 'crashing', 'sea', 'sinks', 'bottom', 'bang', 'middle', 'Bermuda', 'Triangle', 'With', 'air', 'short', 'supply', 'water', 'leaking', 'flown', '200', 'miles', 'course', 'mount', \"survivor's\", 'await', 'help', 'time', 'fast', 'running', 'Also', 'slightly', 'tile', 'Airport', '1977', 'sequel', 'smash-hit', 'disaster', 'thriller', 'Airport', '1970', 'directed', 'Jerry', 'Jameson', \"it's\", 'predecessors', 'I', \"can't\", 'Airport', \"'77\", 'sort', 'forgotten', 'classic', 'entertaining', 'necessarily', 'reasons', 'Out', 'Airport', 'films', 'I', 'seen', 'I', 'actually', 'liked', 'It', 'favourite', 'plot', 'nice', 'mid-air', 'hi-jacking', 'crashing', \"didn't\", 'oil', 'rig', 'sinking', '747', 'maybe', 'makers', 'trying', 'cross', 'original', 'Airport', 'popular', 'disaster', 'flick', 'period', 'The', 'Poseidon', 'Adventure', '1972', 'submerged', 'stays', 'stark', 'dilemma', 'facing', 'trapped', 'inside', 'suffocate', 'air', 'runs', 'drown', '747', 'floods', 'doors', \"it's\", 'decent', 'idea', 'little', 'disaster', 'flick', 'bad', 'unsympathetic', \"character's\", 'dull', 'dialogue', 'lethargic', 'set-pieces', 'real', 'lack', 'danger', 'suspense', 'tension', 'means', 'missed', 'opportunity', 'While', 'sluggish', 'plot', 'entertained', '108', 'odd', 'minutes', 'happens', 'plane', 'sinks', \"there's\", 'urgency', 'I', 'Even', 'Navy', 'involved', \"don't\", 'pick', 'shots', 'huge', 'ships', 'helicopters', 'flying', \"there's\", 'lacking', 'George', 'Kennedy', 'jinxed', 'airline', 'worker', 'Joe', 'Patroni', 'couple', 'scenes', 'barely', 'preferring', 'look', 'worried', 'background', 'The', 'home', 'video', 'theatrical', 'version', 'Airport', \"'77\", 'run', '108', 'minutes', 'US', 'TV', 'versions', 'add', 'extra', 'hour', 'footage', 'including', 'credits', 'sequence', 'scenes', 'George', 'Kennedy', 'Patroni', 'flashbacks', 'flesh', \"character's\", 'rescue', 'scenes', 'discovery', 'couple', 'dead', 'bodies', 'including', 'navigator', 'While', 'I', 'extra', 'footage', 'I', 'am', 'I', 'sit', 'near', 'hour', 'cut', 'Airport', \"'77\", 'As', 'expected', 'film', 'dated', 'badly', 'horrible', 'fashions', 'interior', 'design', 'choices', 'I', 'toy', 'plane', 'model', 'effects', \"aren't\", 'Along', 'Airport', 'sequels', 'takes', 'pride', 'Razzie', \"Award's\", 'Hall', 'Shame', 'I', 'lots', 'worse', 'films', 'I', 'reckon', \"that's\", 'little', 'harsh', 'The', 'action', 'scenes', 'little', 'dull', 'unfortunately', 'pace', 'slow', 'excitement', 'tension', 'generated', 'shame', 'I', 'reckon', 'pretty', 'film', 'properly', 'The', 'production', 'values', 'alright', 'spectacular', 'The', 'acting', \"isn't\", 'time', 'Oscar', 'winner', 'Jack', 'Lemmon', 'mistake', 'star', 'time', 'Oscar', 'winner', 'James', 'Stewart', 'looks', 'frail', 'time', 'Oscar', 'winner', 'Lee', 'Grant', 'looks', 'drunk', 'Sir', 'Christopher', 'Lee', 'little', 'plenty', 'familiar', 'look', 'Airport', \"'77\", 'disaster', 'orientated', 'Airport', 'films', 'I', 'liked', 'ideas', 'bit', 'silly', 'production', 'bland', 'direction', \"doesn't\", 'help', 'film', 'sunken', 'plane', \"shouldn't\", 'boring', 'lethargic', 'Followed', 'The', 'Concorde', 'Airport', \"'79\", '1979']\n",
      "2 -----------\n",
      "['This', 'film', 'lacked', 'I', \"couldn't\", 'finger', 'charisma', 'leading', 'actress', 'This', 'inevitably', 'translated', 'lack', 'chemistry', 'shared', 'screen', 'leading', 'Even', 'romantic', 'scenes', 'merely', 'actors', 'play', 'It', 'director', 'miscalculated', 'actors', 'I', \"don't\", 'But', 'screenplay', 'Just', 'exactly', 'chef', 'love', 'He', 'enamored', 'culinary', 'skills', 'restaurant', 'ultimately', 'youthful', 'exploits', 'else', 'He', 'convinced', 'love', 'princess', 'I', 'disappointed', 'movie', 'But', \"don't\", 'forget', 'nominated', 'Oscar', 'judge', 'yourself']\n",
      "3 -----------\n",
      "['Sorry', 'I', 'supposed', 'art', 'film', 'wow', 'handed', 'guns', 'screening', 'people', 'blow', 'brains', 'watch', 'Although', 'scene', 'design', 'photographic', 'direction', 'excellent', 'story', 'painful', 'watch', 'The', 'absence', 'sound', 'track', 'brutal', 'The', 'loooonnnnng', 'shots', 'How', 'watch', 'people', 'sitting', 'talking', 'Especially', 'dialogue', 'people', 'complaining', 'I', 'hard', 'time', 'getting', 'film', 'The', 'performances', 'excellent', 'dark', 'sombre', 'uninspired', 'stuff', 'The', 'liked', 'Maureen', 'Stapleton', 'red', 'dress', 'dancing', 'scene', 'Otherwise', 'ripoff', 'Bergman', 'And', \"i'm\", 'fan', 'I', 'enjoyed', '1', '1', '2', 'hours', 'lying']\n",
      "4 -----------\n",
      "['When', 'I', 'little', 'parents', 'theater', 'Interiors', 'It', 'movies', 'I', 'watched', 'parents', 'walked', 'Since', 'I', 'seen', 'Interiors', 'recently', 'I', 'lived', 'rest', 'life', 'What', 'pretentious', 'ponderous', 'painfully', 'boring', 'piece', \"70's\", 'wine', 'cheese', 'tripe', 'Woody', 'Allen', 'favorite', 'directors', 'Interiors', 'worst', 'piece', 'crap', 'career', 'In', 'unmistakable', 'style', 'Ingmar', 'Berman', 'Allen', 'dark', 'angular', 'muted', 'insight', 'lives', 'family', 'wrought', 'psychological', 'damage', 'caused', 'divorce', 'estrangement', 'career', 'love', 'non-love', 'halitosis', 'whatever', 'The', 'film', 'intentionally', 'comic', 'relief', 'music', 'drenched', 'shadowy', 'pathos', 'This', 'film', 'style', 'defined', 'expressionist', 'nature', 'using', 'improvisational', 'method', 'dialogue', 'illicit', 'pronounced', 'depth', 'meaning', 'truth', 'But', 'Woody', 'Allen', 'Ingmar', 'Bergman', 'The', 'film', 'painfully', 'slow', 'dull', 'But', 'beyond', 'I', 'simply', 'connection', 'sympathy', 'characters', 'Instead', 'I', 'contempt', 'parade', 'shuffling', 'whining', 'nicotine', 'stained', 'martyrs', 'perpetual', 'quest', 'identity', 'Amid', 'backdrop', 'cosmopolitan', 'affluence', 'baked', 'Brie', 'intelligentsia', 'story', 'looms', 'fart', 'Everyone', 'speaks', 'affected', 'platitudes', 'elevated', 'language', 'cigarettes', 'Everyone', 'lost', 'struggling', 'desperate', 'direction', 'understanding', 'whatever', 'goes', 'slap', \"It's\", 'resolution', \"it's\", 'interminable', 'introspective', 'babble', 'It', 'psychological', 'drama', 'extreme', 'beyond', \"audience's\", 'ability', 'connect', 'Woody', 'Allen', 'chose', 'characters', 'immersed', 'themselves', 'feel', 'left', 'And', 'reason', 'I', 'found', 'movie', 'painfully', 'self', 'indulgent', 'spiritually', 'draining', 'I', 'insistence', 'promoting', 'message', 'Prozac', 'prose', 'distorted', 'film', 'techniques', 'jettisons', 'past', 'relevance', 'I', 'highly', 'recommend', \"you're\", 'feeling', 'little', 'happy', 'remind', 'death', 'Otherwise', \"let's\", 'pretend', 'film', 'happened']\n",
      "\n",
      " neg ================> pos \n",
      "\n",
      "0 -----------\n",
      "['Bromwell', 'High', 'cartoon', 'comedy', 'It', 'ran', 'time', 'programs', 'school', 'life', 'Teachers', 'My', '35', 'teaching', 'profession', 'lead', 'believe', 'Bromwell', \"High's\", 'satire', 'closer', 'reality', 'Teachers', 'The', 'scramble', 'survive', 'financially', 'insightful', 'students', 'pathetic', \"teachers'\", 'pomp', 'pettiness', 'situation', 'remind', 'schools', 'I', 'students', 'When', 'I', 'episode', 'student', 'repeatedly', 'tried', 'burn', 'school', 'I', 'immediately', 'recalled', 'High', 'A', 'classic', 'line', 'INSPECTOR', \"I'm\", 'sack', 'teachers', 'STUDENT', 'Welcome', 'Bromwell', 'High', 'I', 'expect', 'adults', 'age', 'Bromwell', 'High', 'fetched', 'What', 'pity', \"isn't\"]\n",
      "1 -----------\n",
      "['Homelessness', 'Houselessness', 'George', 'Carlin', 'stated', 'issue', 'plan', 'help', 'street', 'considered', 'human', 'school', 'vote', 'matter', 'Most', 'people', 'homeless', 'lost', 'cause', 'worrying', 'racism', 'war', 'Iraq', 'pressuring', 'kids', 'succeed', 'technology', 'elections', 'inflation', 'worrying', \"they'll\", 'streets', 'But', 'bet', 'live', 'streets', 'month', 'luxuries', 'home', 'entertainment', 'sets', 'bathroom', 'pictures', 'wall', 'computer', 'treasure', \"it's\", 'homeless', 'That', 'Goddard', \"Bolt's\", 'lesson', 'Mel', 'Brooks', 'directs', 'stars', 'Bolt', 'plays', 'rich', 'world', 'deciding', 'bet', 'sissy', 'rival', 'Jeffery', 'Tambor', 'live', 'streets', 'thirty', 'days', 'luxuries', 'Bolt', 'succeeds', 'future', 'project', 'buildings', 'The', \"bet's\", 'Bolt', 'thrown', 'street', 'bracelet', 'leg', 'monitor', 'move', \"can't\", 'step', 'sidewalk', \"He's\", 'nickname', 'Pepto', 'vagrant', \"it's\", 'written', 'forehead', 'Bolt', 'meets', 'characters', 'including', 'woman', 'name', 'Molly', 'Lesley', 'Ann', 'Warren', 'ex-dancer', 'divorce', 'losing', 'home', 'pals', 'Sailor', 'Howard', 'Morris', 'Fumes', 'Teddy', 'Wilson', 'streets', \"They're\", 'survivors', 'Bolt', \"isn't\", \"He's\", 'reaching', 'mutual', 'agreements', 'rich', \"it's\", 'fight', 'flight', 'kill', 'killed', 'While', 'love', 'connection', 'Molly', 'Bolt', \"wasn't\", 'plot', 'I', 'found', 'Life', 'Stinks', 'Mel', \"Brooks'\", 'observant', 'films', 'prior', 'comedy', 'tender', 'compared', 'slapstick', 'Blazing', 'Saddles', 'Young', 'Frankenstein', 'Spaceballs', 'matter', \"it's\", 'valuable', 'losing', 'day', 'hand', 'stupid', 'bet', 'rich', 'people', \"don't\", 'money', 'Maybe', 'homeless', 'instead', 'using', 'Monopoly', 'money', 'Or', 'maybe', 'film', 'inspire', 'help']\n",
      "2 -----------\n",
      "['Brilliant', 'over-acting', 'Lesley', 'Ann', 'Warren', 'Best', 'dramatic', 'hobo', 'lady', 'I', 'seen', 'love', 'scenes', 'clothes', 'warehouse', 'none', 'The', 'corn', 'classic', 'Blazing', 'Saddles', 'The', 'lawyers', 'superb', 'After', 'accused', 'turncoat', 'selling', 'boss', 'dishonest', 'lawyer', 'Pepto', 'Bolt', 'shrugs', 'indifferently', \"I'm\", 'lawyer', 'Three', 'funny', 'words', 'Jeffrey', 'Tambor', 'favorite', 'Larry', 'Sanders', 'fantastic', 'mad', 'millionaire', 'crush', 'ghetto', 'His', 'character', 'malevolent', 'usual', 'The', 'hospital', 'scene', 'scene', 'homeless', 'invade', 'demolition', 'site', 'all-time', 'classics', 'Look', 'legs', 'scene', 'diggers', 'fighting', 'bleeds', 'This', 'movie', 'time', 'I']\n",
      "3 -----------\n",
      "['This', 'easily', 'underrated', 'film', 'inn', 'Brooks', 'cannon', 'Sure', 'flawed', 'It', 'realistic', 'view', 'homelessness', 'unlike', 'Citizen', 'Kane', 'realistic', 'view', 'lounge', 'singers', 'Titanic', 'realistic', 'view', 'Italians', 'YOU', 'IDIOTS', 'Many', 'jokes', 'fall', 'flat', 'But', 'film', 'lovable', 'comedies', 'pull', 'story', 'traditionally', 'reviled', 'society', 'truly', 'impressive', 'Its', 'The', 'Fisher', 'King', 'crap', 'My', 'complaint', 'Brooks', 'cast', 'else', 'lead', 'I', 'love', 'Mel', 'Director', 'Writer', 'lead']\n",
      "4 -----------\n",
      "['This', 'typical', 'Mel', 'Brooks', 'film', 'It', 'slapstick', 'movies', 'actually', 'plot', 'followable', 'Leslie', 'Ann', 'Warren', 'movie', 'fantastic', 'under-rated', 'actress', 'There', 'moments', 'fleshed', 'bit', 'scenes', 'probably', 'cut', 'worth', 'price', 'rent', 'The', 'acting', 'overall', 'Brooks', 'job', 'characteristic', 'speaking', 'directly', 'audience', 'Again', 'Warren', 'actor', 'movie', 'Fume', 'Sailor', 'played']\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "****** testing data: ******\n",
      "0 -----------\n",
      "['Story', 'unnatural', 'feelings', 'pig', 'Starts', 'scene', 'terrific', 'example', 'absurd', 'comedy', 'A', 'formal', 'orchestra', 'audience', 'insane', 'violent', 'mob', 'crazy', 'chantings', \"it's\", 'singers', 'Unfortunately', 'stays', 'absurd', 'WHOLE', 'time', 'narrative', 'eventually', 'putting', 'Even', 'era', 'The', 'cryptic', 'dialogue', 'Shakespeare', 'easy', 'third', 'grader', 'On', 'technical', 'level', \"it's\", 'cinematography', 'future', 'Vilmos', 'Zsigmond', 'Future', 'stars', 'Sally', 'Kirkland', 'Frederic', 'Forrest', 'seen', 'briefly']\n",
      "1 -----------\n",
      "['Airport', \"'77\", 'starts', 'brand', 'luxury', '747', 'plane', 'loaded', 'valuable', 'paintings', 'belonging', 'rich', 'businessman', 'Philip', 'Stevens', 'James', 'Stewart', 'flying', 'bunch', \"VIP's\", 'estate', 'preparation', 'public', 'museum', 'board', 'Stevens', 'daughter', 'Julie', 'Kathleen', 'Quinlan', 'son', 'The', 'luxury', 'jetliner', 'takes', 'planned', 'mid-air', 'plane', 'hi-jacked', 'co-pilot', 'Chambers', 'Robert', 'Foxworth', \"accomplice's\", 'Banker', 'Monte', 'Markham', 'Wilson', 'Michael', 'Pataki', 'knock', 'passengers', 'crew', 'sleeping', 'gas', 'plan', 'steal', 'valuable', 'cargo', 'land', 'disused', 'plane', 'strip', 'isolated', 'island', 'descent', 'Chambers', 'hits', 'oil', 'rig', 'Ocean', 'loses', 'control', 'plane', 'sending', 'crashing', 'sea', 'sinks', 'bottom', 'bang', 'middle', 'Bermuda', 'Triangle', 'With', 'air', 'short', 'supply', 'water', 'leaking', 'flown', '200', 'miles', 'course', 'mount', \"survivor's\", 'await', 'help', 'time', 'fast', 'running', 'Also', 'slightly', 'tile', 'Airport', '1977', 'sequel', 'smash-hit', 'disaster', 'thriller', 'Airport', '1970', 'directed', 'Jerry', 'Jameson', \"it's\", 'predecessors', 'I', \"can't\", 'Airport', \"'77\", 'sort', 'forgotten', 'classic', 'entertaining', 'necessarily', 'reasons', 'Out', 'Airport', 'films', 'I', 'seen', 'I', 'actually', 'liked', 'It', 'favourite', 'plot', 'nice', 'mid-air', 'hi-jacking', 'crashing', \"didn't\", 'oil', 'rig', 'sinking', '747', 'maybe', 'makers', 'trying', 'cross', 'original', 'Airport', 'popular', 'disaster', 'flick', 'period', 'The', 'Poseidon', 'Adventure', '1972', 'submerged', 'stays', 'stark', 'dilemma', 'facing', 'trapped', 'inside', 'suffocate', 'air', 'runs', 'drown', '747', 'floods', 'doors', \"it's\", 'decent', 'idea', 'little', 'disaster', 'flick', 'bad', 'unsympathetic', \"character's\", 'dull', 'dialogue', 'lethargic', 'set-pieces', 'real', 'lack', 'danger', 'suspense', 'tension', 'means', 'missed', 'opportunity', 'While', 'sluggish', 'plot', 'entertained', '108', 'odd', 'minutes', 'happens', 'plane', 'sinks', \"there's\", 'urgency', 'I', 'Even', 'Navy', 'involved', \"don't\", 'pick', 'shots', 'huge', 'ships', 'helicopters', 'flying', \"there's\", 'lacking', 'George', 'Kennedy', 'jinxed', 'airline', 'worker', 'Joe', 'Patroni', 'couple', 'scenes', 'barely', 'preferring', 'look', 'worried', 'background', 'The', 'home', 'video', 'theatrical', 'version', 'Airport', \"'77\", 'run', '108', 'minutes', 'US', 'TV', 'versions', 'add', 'extra', 'hour', 'footage', 'including', 'credits', 'sequence', 'scenes', 'George', 'Kennedy', 'Patroni', 'flashbacks', 'flesh', \"character's\", 'rescue', 'scenes', 'discovery', 'couple', 'dead', 'bodies', 'including', 'navigator', 'While', 'I', 'extra', 'footage', 'I', 'am', 'I', 'sit', 'near', 'hour', 'cut', 'Airport', \"'77\", 'As', 'expected', 'film', 'dated', 'badly', 'horrible', 'fashions', 'interior', 'design', 'choices', 'I', 'toy', 'plane', 'model', 'effects', \"aren't\", 'Along', 'Airport', 'sequels', 'takes', 'pride', 'Razzie', \"Award's\", 'Hall', 'Shame', 'I', 'lots', 'worse', 'films', 'I', 'reckon', \"that's\", 'little', 'harsh', 'The', 'action', 'scenes', 'little', 'dull', 'unfortunately', 'pace', 'slow', 'excitement', 'tension', 'generated', 'shame', 'I', 'reckon', 'pretty', 'film', 'properly', 'The', 'production', 'values', 'alright', 'spectacular', 'The', 'acting', \"isn't\", 'time', 'Oscar', 'winner', 'Jack', 'Lemmon', 'mistake', 'star', 'time', 'Oscar', 'winner', 'James', 'Stewart', 'looks', 'frail', 'time', 'Oscar', 'winner', 'Lee', 'Grant', 'looks', 'drunk', 'Sir', 'Christopher', 'Lee', 'little', 'plenty', 'familiar', 'look', 'Airport', \"'77\", 'disaster', 'orientated', 'Airport', 'films', 'I', 'liked', 'ideas', 'bit', 'silly', 'production', 'bland', 'direction', \"doesn't\", 'help', 'film', 'sunken', 'plane', \"shouldn't\", 'boring', 'lethargic', 'Followed', 'The', 'Concorde', 'Airport', \"'79\", '1979']\n",
      "2 -----------\n",
      "['This', 'film', 'lacked', 'I', \"couldn't\", 'finger', 'charisma', 'leading', 'actress', 'This', 'inevitably', 'translated', 'lack', 'chemistry', 'shared', 'screen', 'leading', 'Even', 'romantic', 'scenes', 'merely', 'actors', 'play', 'It', 'director', 'miscalculated', 'actors', 'I', \"don't\", 'But', 'screenplay', 'Just', 'exactly', 'chef', 'love', 'He', 'enamored', 'culinary', 'skills', 'restaurant', 'ultimately', 'youthful', 'exploits', 'else', 'He', 'convinced', 'love', 'princess', 'I', 'disappointed', 'movie', 'But', \"don't\", 'forget', 'nominated', 'Oscar', 'judge', 'yourself']\n",
      "3 -----------\n",
      "['Sorry', 'I', 'supposed', 'art', 'film', 'wow', 'handed', 'guns', 'screening', 'people', 'blow', 'brains', 'watch', 'Although', 'scene', 'design', 'photographic', 'direction', 'excellent', 'story', 'painful', 'watch', 'The', 'absence', 'sound', 'track', 'brutal', 'The', 'loooonnnnng', 'shots', 'How', 'watch', 'people', 'sitting', 'talking', 'Especially', 'dialogue', 'people', 'complaining', 'I', 'hard', 'time', 'getting', 'film', 'The', 'performances', 'excellent', 'dark', 'sombre', 'uninspired', 'stuff', 'The', 'liked', 'Maureen', 'Stapleton', 'red', 'dress', 'dancing', 'scene', 'Otherwise', 'ripoff', 'Bergman', 'And', \"i'm\", 'fan', 'I', 'enjoyed', '1', '1', '2', 'hours', 'lying']\n",
      "4 -----------\n",
      "['When', 'I', 'little', 'parents', 'theater', 'Interiors', 'It', 'movies', 'I', 'watched', 'parents', 'walked', 'Since', 'I', 'seen', 'Interiors', 'recently', 'I', 'lived', 'rest', 'life', 'What', 'pretentious', 'ponderous', 'painfully', 'boring', 'piece', \"70's\", 'wine', 'cheese', 'tripe', 'Woody', 'Allen', 'favorite', 'directors', 'Interiors', 'worst', 'piece', 'crap', 'career', 'In', 'unmistakable', 'style', 'Ingmar', 'Berman', 'Allen', 'dark', 'angular', 'muted', 'insight', 'lives', 'family', 'wrought', 'psychological', 'damage', 'caused', 'divorce', 'estrangement', 'career', 'love', 'non-love', 'halitosis', 'whatever', 'The', 'film', 'intentionally', 'comic', 'relief', 'music', 'drenched', 'shadowy', 'pathos', 'This', 'film', 'style', 'defined', 'expressionist', 'nature', 'using', 'improvisational', 'method', 'dialogue', 'illicit', 'pronounced', 'depth', 'meaning', 'truth', 'But', 'Woody', 'Allen', 'Ingmar', 'Bergman', 'The', 'film', 'painfully', 'slow', 'dull', 'But', 'beyond', 'I', 'simply', 'connection', 'sympathy', 'characters', 'Instead', 'I', 'contempt', 'parade', 'shuffling', 'whining', 'nicotine', 'stained', 'martyrs', 'perpetual', 'quest', 'identity', 'Amid', 'backdrop', 'cosmopolitan', 'affluence', 'baked', 'Brie', 'intelligentsia', 'story', 'looms', 'fart', 'Everyone', 'speaks', 'affected', 'platitudes', 'elevated', 'language', 'cigarettes', 'Everyone', 'lost', 'struggling', 'desperate', 'direction', 'understanding', 'whatever', 'goes', 'slap', \"It's\", 'resolution', \"it's\", 'interminable', 'introspective', 'babble', 'It', 'psychological', 'drama', 'extreme', 'beyond', \"audience's\", 'ability', 'connect', 'Woody', 'Allen', 'chose', 'characters', 'immersed', 'themselves', 'feel', 'left', 'And', 'reason', 'I', 'found', 'movie', 'painfully', 'self', 'indulgent', 'spiritually', 'draining', 'I', 'insistence', 'promoting', 'message', 'Prozac', 'prose', 'distorted', 'film', 'techniques', 'jettisons', 'past', 'relevance', 'I', 'highly', 'recommend', \"you're\", 'feeling', 'little', 'happy', 'remind', 'death', 'Otherwise', \"let's\", 'pretend', 'film', 'happened']\n",
      "\n",
      " neg ================> pos \n",
      "\n",
      "0 -----------\n",
      "['Bromwell', 'High', 'cartoon', 'comedy', 'It', 'ran', 'time', 'programs', 'school', 'life', 'Teachers', 'My', '35', 'teaching', 'profession', 'lead', 'believe', 'Bromwell', \"High's\", 'satire', 'closer', 'reality', 'Teachers', 'The', 'scramble', 'survive', 'financially', 'insightful', 'students', 'pathetic', \"teachers'\", 'pomp', 'pettiness', 'situation', 'remind', 'schools', 'I', 'students', 'When', 'I', 'episode', 'student', 'repeatedly', 'tried', 'burn', 'school', 'I', 'immediately', 'recalled', 'High', 'A', 'classic', 'line', 'INSPECTOR', \"I'm\", 'sack', 'teachers', 'STUDENT', 'Welcome', 'Bromwell', 'High', 'I', 'expect', 'adults', 'age', 'Bromwell', 'High', 'fetched', 'What', 'pity', \"isn't\"]\n",
      "1 -----------\n",
      "['Homelessness', 'Houselessness', 'George', 'Carlin', 'stated', 'issue', 'plan', 'help', 'street', 'considered', 'human', 'school', 'vote', 'matter', 'Most', 'people', 'homeless', 'lost', 'cause', 'worrying', 'racism', 'war', 'Iraq', 'pressuring', 'kids', 'succeed', 'technology', 'elections', 'inflation', 'worrying', \"they'll\", 'streets', 'But', 'bet', 'live', 'streets', 'month', 'luxuries', 'home', 'entertainment', 'sets', 'bathroom', 'pictures', 'wall', 'computer', 'treasure', \"it's\", 'homeless', 'That', 'Goddard', \"Bolt's\", 'lesson', 'Mel', 'Brooks', 'directs', 'stars', 'Bolt', 'plays', 'rich', 'world', 'deciding', 'bet', 'sissy', 'rival', 'Jeffery', 'Tambor', 'live', 'streets', 'thirty', 'days', 'luxuries', 'Bolt', 'succeeds', 'future', 'project', 'buildings', 'The', \"bet's\", 'Bolt', 'thrown', 'street', 'bracelet', 'leg', 'monitor', 'move', \"can't\", 'step', 'sidewalk', \"He's\", 'nickname', 'Pepto', 'vagrant', \"it's\", 'written', 'forehead', 'Bolt', 'meets', 'characters', 'including', 'woman', 'name', 'Molly', 'Lesley', 'Ann', 'Warren', 'ex-dancer', 'divorce', 'losing', 'home', 'pals', 'Sailor', 'Howard', 'Morris', 'Fumes', 'Teddy', 'Wilson', 'streets', \"They're\", 'survivors', 'Bolt', \"isn't\", \"He's\", 'reaching', 'mutual', 'agreements', 'rich', \"it's\", 'fight', 'flight', 'kill', 'killed', 'While', 'love', 'connection', 'Molly', 'Bolt', \"wasn't\", 'plot', 'I', 'found', 'Life', 'Stinks', 'Mel', \"Brooks'\", 'observant', 'films', 'prior', 'comedy', 'tender', 'compared', 'slapstick', 'Blazing', 'Saddles', 'Young', 'Frankenstein', 'Spaceballs', 'matter', \"it's\", 'valuable', 'losing', 'day', 'hand', 'stupid', 'bet', 'rich', 'people', \"don't\", 'money', 'Maybe', 'homeless', 'instead', 'using', 'Monopoly', 'money', 'Or', 'maybe', 'film', 'inspire', 'help']\n",
      "2 -----------\n",
      "['Brilliant', 'over-acting', 'Lesley', 'Ann', 'Warren', 'Best', 'dramatic', 'hobo', 'lady', 'I', 'seen', 'love', 'scenes', 'clothes', 'warehouse', 'none', 'The', 'corn', 'classic', 'Blazing', 'Saddles', 'The', 'lawyers', 'superb', 'After', 'accused', 'turncoat', 'selling', 'boss', 'dishonest', 'lawyer', 'Pepto', 'Bolt', 'shrugs', 'indifferently', \"I'm\", 'lawyer', 'Three', 'funny', 'words', 'Jeffrey', 'Tambor', 'favorite', 'Larry', 'Sanders', 'fantastic', 'mad', 'millionaire', 'crush', 'ghetto', 'His', 'character', 'malevolent', 'usual', 'The', 'hospital', 'scene', 'scene', 'homeless', 'invade', 'demolition', 'site', 'all-time', 'classics', 'Look', 'legs', 'scene', 'diggers', 'fighting', 'bleeds', 'This', 'movie', 'time', 'I']\n",
      "3 -----------\n",
      "['This', 'easily', 'underrated', 'film', 'inn', 'Brooks', 'cannon', 'Sure', 'flawed', 'It', 'realistic', 'view', 'homelessness', 'unlike', 'Citizen', 'Kane', 'realistic', 'view', 'lounge', 'singers', 'Titanic', 'realistic', 'view', 'Italians', 'YOU', 'IDIOTS', 'Many', 'jokes', 'fall', 'flat', 'But', 'film', 'lovable', 'comedies', 'pull', 'story', 'traditionally', 'reviled', 'society', 'truly', 'impressive', 'Its', 'The', 'Fisher', 'King', 'crap', 'My', 'complaint', 'Brooks', 'cast', 'else', 'lead', 'I', 'love', 'Mel', 'Director', 'Writer', 'lead']\n",
      "4 -----------\n",
      "['This', 'typical', 'Mel', 'Brooks', 'film', 'It', 'slapstick', 'movies', 'actually', 'plot', 'followable', 'Leslie', 'Ann', 'Warren', 'movie', 'fantastic', 'under-rated', 'actress', 'There', 'moments', 'fleshed', 'bit', 'scenes', 'probably', 'cut', 'worth', 'price', 'rent', 'The', 'acting', 'overall', 'Brooks', 'job', 'characteristic', 'speaking', 'directly', 'audience', 'Again', 'Warren', 'actor', 'movie', 'Fume', 'Sailor', 'played']\n"
     ]
    }
   ],
   "source": [
    "print '****** training data: ******'\n",
    "for i, tx in enumerate(X_train['neg'][0:5]):\n",
    "    print '%d -----------' % i\n",
    "    print tx\n",
    "       \n",
    "print '\\n neg ================> pos \\n'\n",
    "\n",
    "for i, tx in enumerate(X_train['pos'][0:5]):\n",
    "    print '%d -----------' % i\n",
    "    print tx\n",
    "\n",
    "print '\\n------------------------------------------\\n'\n",
    "\n",
    "print '****** testing data: ******'    \n",
    "for i, tx in enumerate(X_train['neg'][0:5]):\n",
    "    print '%d -----------' % i\n",
    "    print tx\n",
    "       \n",
    "print '\\n neg ================> pos \\n'\n",
    "\n",
    "for i, tx in enumerate(X_train['pos'][0:5]):\n",
    "    print '%d -----------' % i\n",
    "    print tx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vl = []\n",
    "for d in ['neg', 'pos']:\n",
    "    for doc in X_train[d]:\n",
    "        for wd in doc:\n",
    "            vl.append(wd)\n",
    "        \n",
    "voc_list = list(set(vl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127583"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
