{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Process\n",
    "\n",
    "Assume the task we want to classify is determining the label $y$ of observed data $X=(x_1, x_2)$, where $x_1, x_2$ are the attributes of $X$. Further, we assume attribute $x_1 \\in A_1 = \\{1, 2, 3\\}$ and attribute $x_2 \\in A_2 = \\{S, M, L\\}$. And the label $y \\in C = \\{1, -1\\}$. The observed data and labels are below.\n",
    "\n",
    "The assumed problem is to predict the data $X = \\{2, S\\}^T$, which is supposed to get estimation value $-1$ based on the Multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_random: \n",
      "{'data': [[3, 'M'], [2, 'M'], [1, 'S'], [2, 'S'], [1, 'L'], [2, 'S'], [2, 'S'], [2, 'M'], [3, 'L'], [1, 'M'], [3, 'M'], [3, 'M'], [3, 'L'], [2, 'L'], [1, 'S']], 'target': [-1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1]}\n",
      "data_hard_code: \n",
      "{'data': [[1, 'S'], [1, 'M'], [1, 'M'], [1, 'S'], [1, 'S'], [2, 'S'], [2, 'M'], [2, 'M'], [2, 'L'], [2, 'L'], [3, 'L'], [3, 'M'], [3, 'M'], [3, 'L'], [3, 'L']], 'target': [-1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1]}\n"
     ]
    }
   ],
   "source": [
    "import gen_synthetic as gs\n",
    "\n",
    "# Test the randomly generated data\n",
    "x1_dom = [1, 2, 3]\n",
    "x2_dom = ['S', 'M', 'L']\n",
    "x_dom = [x1_dom, x2_dom]\n",
    "y_dom = [-1, 1]\n",
    "\n",
    "data_random = gs.gen_naive_bayes_synthetic(x_dom, y_dom, 15)\n",
    "print 'data_random: \\n', data_random\n",
    "\n",
    "# Test embedded hard code data\n",
    "data_hard_code = gs.gen_naive_bayes_synthetic([], [], 0, hard_code=True)\n",
    "print 'data_hard_code: \\n', data_hard_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1   3\n",
      "0  1  1  10\n",
      "1  2  2  20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tt = np.array([[1, 1], [2, 2]])\n",
    "df = pd.DataFrame(tt)\n",
    "ty = np.array([10, 20])\n",
    "df[3] = ty\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes without Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1  2\n",
      "2   1  S  1\n",
      "4   1  L  1\n",
      "9   1  M -1\n",
      "14  1  S -1\n"
     ]
    }
   ],
   "source": [
    "from classifiers import MultinomialNB\n",
    "mnNB = MultinomialNB()\n",
    "\n",
    "mnNB.train(np.array(data_random['data']), np.array(data_random['target']))\n",
    "df = mnNB.counts_table\n",
    "print df[df[0] == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1  2\n",
      "0   1  S -1\n",
      "1   1  M -1\n",
      "2   1  M  1\n",
      "3   1  S  1\n",
      "4   1  S -1\n",
      "5   2  S -1\n",
      "6   2  M -1\n",
      "7   2  M  1\n",
      "8   2  L  1\n",
      "9   2  L  1\n",
      "10  3  L  1\n",
      "11  3  M  1\n",
      "12  3  M  1\n",
      "13  3  L  1\n",
      "14  3  L -1\n",
      "   0  1  2\n",
      "0  1  S -1\n",
      "1  1  M -1\n",
      "2  1  M  1\n",
      "3  1  S  1\n",
      "4  1  S -1\n",
      "number of above rows:  5\n",
      "   0  1  2\n",
      "1  1  M -1\n",
      "2  1  M  1\n",
      "number of above rows:  2\n",
      "number of non-existing rows: 0\n",
      "\n",
      "The probability table is:\n",
      "k = -1, prob = 0.400000\n",
      "k = 1, prob = 0.600000\n",
      "k = 1|-1, prob = 0.222222\n",
      "k = 1|1, prob = 0.333333\n",
      "k = 2|-1, prob = 0.333333\n",
      "k = 2|1, prob = 0.500000\n",
      "k = 3|-1, prob = 0.444444\n",
      "k = 3|1, prob = 0.166667\n",
      "k = L|-1, prob = 0.222222\n",
      "k = L|1, prob = 0.333333\n",
      "k = M|-1, prob = 0.444444\n",
      "k = M|1, prob = 0.333333\n",
      "k = S|-1, prob = 0.333333\n",
      "k = S|1, prob = 0.333333\n"
     ]
    }
   ],
   "source": [
    "mnNB.train(np.array(data_hard_code['data']), np.array(data_hard_code['target']))\n",
    "df = mnNB.counts_table\n",
    "print df\n",
    "print df[df[0] == '1']\n",
    "print 'number of above rows: ', len(df[df[0] == '1'])\n",
    "\n",
    "print df[(df[0] == '1') & (df[1] == 'M')]\n",
    "print 'number of above rows: ', len(df[(df[0] == '1') & (df[1] == 'M')])\n",
    "\n",
    "print 'number of non-existing rows:', len(df[df[0] == '7'])\n",
    "\n",
    "print '\\nThe probability table is:'\n",
    "for k in sorted(mnNB.prob_table):\n",
    "    print 'k = %s, prob = %f' % (k, mnNB.prob_table[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2\n",
      "0  1  S -1\n",
      "1  1  M -1\n",
      "2  1  M  1\n",
      "3  1  S  1\n",
      "4  1  S -1\n",
      "number of above rows:  5\n",
      "   0  1  2\n",
      "1  1  M -1\n",
      "2  1  M  1\n",
      "number of above rows:  5\n",
      "number of non-existing rows: 0\n",
      "\n",
      "The probability table is:\n",
      "k = -1, prob = 0.400000\n",
      "k = 1, prob = 0.600000\n",
      "k = 1|-1, prob = 0.222222\n",
      "k = 1|1, prob = 0.333333\n",
      "k = 2|-1, prob = 0.333333\n",
      "k = 2|1, prob = 0.500000\n",
      "k = 3|-1, prob = 0.444444\n",
      "k = 3|1, prob = 0.166667\n",
      "k = L|-1, prob = 0.222222\n",
      "k = L|1, prob = 0.333333\n",
      "k = M|-1, prob = 0.444444\n",
      "k = M|1, prob = 0.333333\n",
      "k = S|-1, prob = 0.333333\n",
      "k = S|1, prob = 0.333333\n"
     ]
    }
   ],
   "source": [
    "mnNB.train(np.array(data_hard_code['data']), np.array(data_hard_code['target']), laplaceS=1.0)\n",
    "df = mnNB.counts_table\n",
    "print df[df[0] == '1']\n",
    "print 'number of above rows: ', len(df[df[0] == '1'])\n",
    "\n",
    "print df[(df[0] == '1') & (df[1] == 'M')]\n",
    "print 'number of above rows: ', len(df[df[0] == '1'])\n",
    "\n",
    "print 'number of non-existing rows:', len(df[df[0] == '7'])\n",
    "\n",
    "print '\\nThe probability table is:'\n",
    "for k in sorted(mnNB.prob_table):\n",
    "    print 'k = %s, prob = %f' % (k, mnNB.prob_table[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "XX_test = [2, 'S']\n",
    "mnNB.predict(np.array(XX_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "As part of this problem, you will implement a Naive Bayes classifier for classifying movie reviews as positive or negative. The dataset that you will be using is the IMDB Large Movie Review dataset (Maas et. al, ACL 2011). The processed dataset can be found [here](https://www.dropbox.com/s/liz0o40f5mpj8ye/hw1_dataset_nb.tar.gz?dl=0). The task is to estimate appropriate parameters using the training data, and use it to predict reviews from the test data, and classify each of them as either positive or negative.\n",
    "\n",
    "We employ the *Multinomial Naive Bayes model for modeling each $P(X_i | Y = y_k)$ ($i = 1 .. n$), with appropriate word counts* (Note $n$ is the number of dimensions).\n",
    "\n",
    "Please use Matlab, Python, R, C/C++ or Java for your implementation. Note that you will have to submit your codes in Autolab, and provide the answers to the questions in the below subsections in your report.\n",
    "\n",
    "### Preprocessing\n",
    "The dataset is partitioned into 2 folders: `train` and `test`, each of which contains 2 subfolders (`pos` and `neg`, for positive and negative samples respectively). The content of each file has to be converted to a bag-of-words representation. So the first task is to go through all the files in the `train` folder, and construct the vocabulary $V$ of all unique words. Please ignore all the stop-words as given in the file `sw.txt` (provided along with the dataset). The words from each file (both in training and testing phase) must be extracted by splitting the raw text only with whitespace characters and {\\color{red}converting them to lowercase characters}. \n",
    "\n",
    "The next step is to get counts of each individual words for the positive and the negative classes separately, to get $P(word | class)$. \n",
    "\n",
    "### Classification\n",
    "In this step, you need to go through all the negative and positive samples in the test data, and classify each sample according to the parameters learned earlier. The classification should be done by comparing the log-posterior (un-normalized), which is given by $\\log(P(X|Y)P(Y))$, for both the classes.\n",
    "\n",
    "### Laplace smoothing\n",
    "An issue with the original Naive Bayes setup is that if a test sample contains a word which is not present in the dictionary, the $P(word|label)$ goes to $0$. To mitigate this issue, one solution is to employ Laplace smoothing (it has a parameter $\\alpha$). Augment your $P(word | class)$ calculations by including the appropriate terms for doing Laplace smoothing. \n",
    "\n",
    "Report the confusion matrix and overall accuracy of your classifier on the test dataset with $\\alpha = 1$. Recall that the confusion matrix for such 2-class classification problem, is a matrix of the number of true positives (positive samples correctly classified as positive), number of true negatives (negative samples correctly classified as negative), number of false positives (negative samples incorrectly classified as positive), and number of false negatives (positive samples incorrectly classified as negative). The accuracy is the ratio of sum of true positives and true negatives, and the total number of samples (in the test dataset).\n",
    "\n",
    "Now vary the value of $\\alpha$ from $0.0001$ to $1000$ (by multiplying $\\alpha$ with 10 each time), and report a plot of the accuracy on the test dataset for the corresponding values of $\\alpha$. (The x-axis should represent $\\alpha$ values and use a $\\log$ scale for the x-axis).\n",
    "\n",
    " Why do you think the accuracy suffers when $\\alpha$ is too high or too low? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story of a man who has unnatural feelings for a pig  Starts out with a opening scene that is a terrific example of absurd comedy  A formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it's singers  Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting  Even those from the era should be turned off  The cryptic dialogue would make Shakespeare seem easy to a third grader  On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond  Future stars Sally Kirkland and Frederic Forrest can be seen briefly \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "fileName = '0_3.txt'\n",
    "dataPath = os.path.join('dataset', 'hw1_dataset_nb', 'train', 'neg', fileName)\n",
    "data = open(dataPath, 'r').read()\n",
    "print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training, testing data and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get IMDB data\n",
    "def getIMDBData(dirPre, dataLabel):\n",
    "    res = {}\n",
    "    for dl in dataLabel:\n",
    "        dirPath = os.path.join(dirPre, dl)\n",
    "        fileNames = os.listdir(dirPath)\n",
    "\n",
    "        docs = []\n",
    "        for fN in fileNames:\n",
    "            doc = open(os.path.join(dirPath, fN), 'r').read()\n",
    "            docs.append(doc)\n",
    "            \n",
    "        res[dl] = docs\n",
    "        \n",
    "    return res\n",
    "    \n",
    "dataPathPre = os.path.join('dataset', 'hw1_dataset_nb')\n",
    "devType = ['train', 'test']\n",
    "dataLabel = ['pos', 'neg']\n",
    "\n",
    "IMDB_train = getIMDBData(os.path.join(dataPathPre, devType[0]), dataLabel)\n",
    "IMDB_test = getIMDBData(os.path.join(dataPathPre, devType[1]), dataLabel)\n",
    "IMDB_stop_words = open(os.path.join(dataPathPre, 'sw.txt'), 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert text data to words list\n",
    "from dataset import removePunctuation\n",
    "\n",
    "def doc2WordList(X, dataLabel, sw):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    -----\n",
    "    - X: dict contains 'pos' and 'neg', which is defined in dataLabel.\n",
    "         Each X[dataLabel[0]] contains docs list, i.e. [doc1, doc2, ..., docN]\n",
    "    \n",
    "    Remove punctuations, and make words in lowercase.\n",
    "    \"\"\"\n",
    "    res_X = {}\n",
    "    \n",
    "    for dl in dataLabel:\n",
    "        res_X[dl] = []\n",
    "        for doc in X[dl]:\n",
    "            res_X[dl].append([x for x in removePunctuation(doc).split() if (not x in sw) and (len(x) > 0)])\n",
    "            \n",
    "    return res_X\n",
    "\n",
    "stop_words = IMDB_stop_words.split()\n",
    "X_train_list = doc2WordList(IMDB_train, dataLabel, stop_words)\n",
    "X_test_list = doc2WordList(IMDB_test, dataLabel, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'across', 'after']\n"
     ]
    }
   ],
   "source": [
    "print stop_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['story', 'unnatural', 'feelings', 'pig', 'starts', 'scene', 'terrific', 'example', 'absurd', 'comedy', 'formal', 'orchestra', 'audience', 'insane', 'violent', 'mob', 'crazy', 'chantings', 'singers', 'unfortunately', 'stays', 'absurd', 'time', 'narrative', 'eventually', 'putting', 'era', 'cryptic', 'dialogue', 'shakespeare', 'easy', 'third', 'grader', 'technical', 'level', 'cinematography', 'future', 'vilmos', 'zsigmond', 'future', 'stars', 'sally', 'kirkland', 'frederic', 'forrest', 'seen', 'briefly']\n"
     ]
    }
   ],
   "source": [
    "print X_train_list['neg'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** training data: ******\n",
      "0 -----------\n",
      "['story', 'unnatural', 'feelings', 'pig', 'starts', 'scene', 'terrific', 'example', 'absurd', 'comedy', 'formal', 'orchestra', 'audience', 'insane', 'violent', 'mob', 'crazy', 'chantings', 'singers', 'unfortunately', 'stays', 'absurd', 'time', 'narrative', 'eventually', 'putting', 'era', 'cryptic', 'dialogue', 'shakespeare', 'easy', 'third', 'grader', 'technical', 'level', 'cinematography', 'future', 'vilmos', 'zsigmond', 'future', 'stars', 'sally', 'kirkland', 'frederic', 'forrest', 'seen', 'briefly']\n",
      "1 -----------\n",
      "['airport', '77', 'starts', 'brand', 'luxury', '747', 'plane', 'loaded', 'valuable', 'paintings', 'belonging', 'rich', 'businessman', 'philip', 'stevens', 'james', 'stewart', 'flying', 'bunch', 'vips', 'estate', 'preparation', 'public', 'museum', 'board', 'stevens', 'daughter', 'julie', 'kathleen', 'quinlan', 'son', 'luxury', 'jetliner', 'takes', 'planned', 'midair', 'plane', 'hijacked', 'copilot', 'chambers', 'robert', 'foxworth', 'accomplices', 'banker', 'monte', 'markham', 'wilson', 'michael', 'pataki', 'knock', 'passengers', 'crew', 'sleeping', 'gas', 'plan', 'steal', 'valuable', 'cargo', 'land', 'disused', 'plane', 'strip', 'isolated', 'island', 'descent', 'chambers', 'hits', 'oil', 'rig', 'ocean', 'loses', 'control', 'plane', 'sending', 'crashing', 'sea', 'sinks', 'bottom', 'bang', 'middle', 'bermuda', 'triangle', 'air', 'short', 'supply', 'water', 'leaking', 'flown', '200', 'miles', 'course', 'mount', 'survivors', 'await', 'help', 'time', 'fast', 'running', 'slightly', 'tile', 'airport', '1977', 'sequel', 'smashhit', 'disaster', 'thriller', 'airport', '1970', 'directed', 'jerry', 'jameson', 'predecessors', 'cant', 'airport', '77', 'sort', 'forgotten', 'classic', 'entertaining', 'necessarily', 'reasons', 'airport', 'films', 'seen', 'actually', 'liked', 'favourite', 'plot', 'nice', 'midair', 'hijacking', 'crashing', 'didnt', 'oil', 'rig', 'sinking', '747', 'maybe', 'makers', 'trying', 'cross', 'original', 'airport', 'popular', 'disaster', 'flick', 'period', 'poseidon', 'adventure', '1972', 'submerged', 'stays', 'stark', 'dilemma', 'facing', 'trapped', 'inside', 'suffocate', 'air', 'runs', 'drown', '747', 'floods', 'doors', 'decent', 'idea', 'little', 'disaster', 'flick', 'bad', 'unsympathetic', 'characters', 'dull', 'dialogue', 'lethargic', 'setpieces', 'real', 'lack', 'danger', 'suspense', 'tension', 'means', 'missed', 'opportunity', 'sluggish', 'plot', 'entertained', '108', 'odd', 'minutes', 'happens', 'plane', 'sinks', 'theres', 'urgency', 'navy', 'involved', 'dont', 'pick', 'shots', 'huge', 'ships', 'helicopters', 'flying', 'theres', 'lacking', 'george', 'kennedy', 'jinxed', 'airline', 'worker', 'joe', 'patroni', 'couple', 'scenes', 'barely', 'preferring', 'look', 'worried', 'background', 'home', 'video', 'theatrical', 'version', 'airport', '77', 'run', '108', 'minutes', 'tv', 'versions', 'add', 'extra', 'hour', 'footage', 'including', 'credits', 'sequence', 'scenes', 'george', 'kennedy', 'patroni', 'flashbacks', 'flesh', 'characters', 'rescue', 'scenes', 'discovery', 'couple', 'dead', 'bodies', 'including', 'navigator', 'extra', 'footage', 'am', 'sit', 'near', 'hour', 'cut', 'airport', '77', 'expected', 'film', 'dated', 'badly', 'horrible', 'fashions', 'interior', 'design', 'choices', 'toy', 'plane', 'model', 'effects', 'arent', 'airport', 'sequels', 'takes', 'pride', 'razzie', 'awards', 'hall', 'shame', 'lots', 'worse', 'films', 'reckon', 'thats', 'little', 'harsh', 'action', 'scenes', 'little', 'dull', 'unfortunately', 'pace', 'slow', 'excitement', 'tension', 'generated', 'shame', 'reckon', 'pretty', 'film', 'properly', 'production', 'values', 'alright', 'spectacular', 'acting', 'isnt', 'time', 'oscar', 'winner', 'jack', 'lemmon', 'mistake', 'star', 'time', 'oscar', 'winner', 'james', 'stewart', 'looks', 'frail', 'time', 'oscar', 'winner', 'lee', 'grant', 'looks', 'drunk', 'sir', 'christopher', 'lee', 'little', 'plenty', 'familiar', 'look', 'airport', '77', 'disaster', 'orientated', 'airport', 'films', 'liked', 'ideas', 'bit', 'silly', 'production', 'bland', 'direction', 'doesnt', 'help', 'film', 'sunken', 'plane', 'shouldnt', 'boring', 'lethargic', 'followed', 'concorde', 'airport', '79', '1979']\n",
      "2 -----------\n",
      "['film', 'lacked', 'couldnt', 'finger', 'charisma', 'leading', 'actress', 'inevitably', 'translated', 'lack', 'chemistry', 'shared', 'screen', 'leading', 'romantic', 'scenes', 'merely', 'actors', 'play', 'director', 'miscalculated', 'actors', 'dont', 'screenplay', 'exactly', 'chef', 'love', 'enamored', 'culinary', 'skills', 'restaurant', 'ultimately', 'youthful', 'exploits', 'else', 'convinced', 'love', 'princess', 'disappointed', 'movie', 'dont', 'forget', 'nominated', 'oscar', 'judge', 'yourself']\n",
      "3 -----------\n",
      "['sorry', 'supposed', 'art', 'film', 'wow', 'handed', 'guns', 'screening', 'people', 'blow', 'brains', 'watch', 'scene', 'design', 'photographic', 'direction', 'excellent', 'story', 'painful', 'watch', 'absence', 'sound', 'track', 'brutal', 'loooonnnnng', 'shots', 'watch', 'people', 'sitting', 'talking', 'especially', 'dialogue', 'people', 'complaining', 'hard', 'time', 'getting', 'film', 'performances', 'excellent', 'dark', 'sombre', 'uninspired', 'stuff', 'liked', 'maureen', 'stapleton', 'red', 'dress', 'dancing', 'scene', 'otherwise', 'ripoff', 'bergman', 'im', 'fan', 'enjoyed', '1', '1', '2', 'hours', 'lying']\n",
      "4 -----------\n",
      "['little', 'parents', 'theater', 'interiors', 'movies', 'watched', 'parents', 'walked', 'seen', 'interiors', 'recently', 'lived', 'rest', 'life', 'pretentious', 'ponderous', 'painfully', 'boring', 'piece', '70s', 'wine', 'cheese', 'tripe', 'woody', 'allen', 'favorite', 'directors', 'interiors', 'worst', 'piece', 'crap', 'career', 'unmistakable', 'style', 'ingmar', 'berman', 'allen', 'dark', 'angular', 'muted', 'insight', 'lives', 'family', 'wrought', 'psychological', 'damage', 'caused', 'divorce', 'estrangement', 'career', 'love', 'nonlove', 'halitosis', 'whatever', 'film', 'intentionally', 'comic', 'relief', 'music', 'drenched', 'shadowy', 'pathos', 'film', 'style', 'defined', 'expressionist', 'nature', 'using', 'improvisational', 'method', 'dialogue', 'illicit', 'pronounced', 'depth', 'meaning', 'truth', 'woody', 'allen', 'ingmar', 'bergman', 'film', 'painfully', 'slow', 'dull', 'beyond', 'simply', 'connection', 'sympathy', 'characters', 'instead', 'contempt', 'parade', 'shuffling', 'whining', 'nicotine', 'stained', 'martyrs', 'perpetual', 'quest', 'identity', 'amid', 'backdrop', 'cosmopolitan', 'affluence', 'baked', 'brie', 'intelligentsia', 'story', 'looms', 'fart', 'speaks', 'affected', 'platitudes', 'elevated', 'language', 'cigarettes', 'lost', 'struggling', 'desperate', 'direction', 'understanding', 'whatever', 'goes', 'slap', 'resolution', 'interminable', 'introspective', 'babble', 'psychological', 'drama', 'extreme', 'beyond', 'audiences', 'ability', 'connect', 'woody', 'allen', 'chose', 'characters', 'immersed', 'themselves', 'feel', 'left', 'reason', 'found', 'movie', 'painfully', 'self', 'indulgent', 'spiritually', 'draining', 'insistence', 'promoting', 'message', 'prozac', 'prose', 'distorted', 'film', 'techniques', 'jettisons', 'past', 'relevance', 'highly', 'recommend', 'youre', 'feeling', 'little', 'happy', 'remind', 'death', 'otherwise', 'pretend', 'film', 'happened']\n",
      "\n",
      " neg ================> pos \n",
      "\n",
      "0 -----------\n",
      "['bromwell', 'cartoon', 'comedy', 'ran', 'time', 'programs', 'school', 'life', 'teachers', '35', 'teaching', 'profession', 'lead', 'believe', 'bromwell', 'highs', 'satire', 'closer', 'reality', 'teachers', 'scramble', 'survive', 'financially', 'insightful', 'students', 'pathetic', 'teachers', 'pomp', 'pettiness', 'situation', 'remind', 'schools', 'students', 'episode', 'student', 'repeatedly', 'tried', 'burn', 'school', 'immediately', 'recalled', 'classic', 'line', 'inspector', 'im', 'sack', 'teachers', 'student', 'welcome', 'bromwell', 'expect', 'adults', 'age', 'bromwell', 'fetched', 'pity', 'isnt']\n",
      "1 -----------\n",
      "['homelessness', 'houselessness', 'george', 'carlin', 'stated', 'issue', 'plan', 'help', 'street', 'considered', 'human', 'school', 'vote', 'matter', 'people', 'homeless', 'lost', 'cause', 'worrying', 'racism', 'war', 'iraq', 'pressuring', 'kids', 'succeed', 'technology', 'elections', 'inflation', 'worrying', 'theyll', 'streets', 'bet', 'live', 'streets', 'month', 'luxuries', 'home', 'entertainment', 'sets', 'bathroom', 'pictures', 'wall', 'computer', 'treasure', 'homeless', 'goddard', 'bolts', 'lesson', 'mel', 'brooks', 'directs', 'stars', 'bolt', 'plays', 'rich', 'world', 'deciding', 'bet', 'sissy', 'rival', 'jeffery', 'tambor', 'live', 'streets', 'thirty', 'days', 'luxuries', 'bolt', 'succeeds', 'future', 'project', 'buildings', 'bets', 'bolt', 'thrown', 'street', 'bracelet', 'leg', 'monitor', 'move', 'cant', 'step', 'sidewalk', 'hes', 'nickname', 'pepto', 'vagrant', 'written', 'forehead', 'bolt', 'meets', 'characters', 'including', 'woman', 'name', 'molly', 'lesley', 'ann', 'warren', 'exdancer', 'divorce', 'losing', 'home', 'pals', 'sailor', 'howard', 'morris', 'fumes', 'teddy', 'wilson', 'streets', 'theyre', 'survivors', 'bolt', 'isnt', 'hes', 'reaching', 'mutual', 'agreements', 'rich', 'fight', 'flight', 'kill', 'killed', 'love', 'connection', 'molly', 'bolt', 'wasnt', 'plot', 'found', 'life', 'stinks', 'mel', 'brooks', 'observant', 'films', 'prior', 'comedy', 'tender', 'compared', 'slapstick', 'blazing', 'saddles', 'frankenstein', 'spaceballs', 'matter', 'valuable', 'losing', 'day', 'hand', 'stupid', 'bet', 'rich', 'people', 'dont', 'money', 'maybe', 'homeless', 'instead', 'using', 'monopoly', 'money', 'maybe', 'film', 'inspire', 'help']\n",
      "2 -----------\n",
      "['brilliant', 'overacting', 'lesley', 'ann', 'warren', 'dramatic', 'hobo', 'lady', 'seen', 'love', 'scenes', 'clothes', 'warehouse', 'none', 'corn', 'classic', 'blazing', 'saddles', 'lawyers', 'superb', 'accused', 'turncoat', 'selling', 'boss', 'dishonest', 'lawyer', 'pepto', 'bolt', 'shrugs', 'indifferently', 'im', 'lawyer', 'funny', 'words', 'jeffrey', 'tambor', 'favorite', 'larry', 'sanders', 'fantastic', 'mad', 'millionaire', 'crush', 'ghetto', 'character', 'malevolent', 'usual', 'hospital', 'scene', 'scene', 'homeless', 'invade', 'demolition', 'site', 'alltime', 'classics', 'look', 'legs', 'scene', 'diggers', 'fighting', 'bleeds', 'movie', 'time']\n",
      "3 -----------\n",
      "['easily', 'underrated', 'film', 'inn', 'brooks', 'cannon', 'flawed', 'realistic', 'view', 'homelessness', 'unlike', 'citizen', 'kane', 'realistic', 'view', 'lounge', 'singers', 'titanic', 'realistic', 'view', 'italians', 'idiots', 'jokes', 'fall', 'flat', 'film', 'lovable', 'comedies', 'pull', 'story', 'traditionally', 'reviled', 'society', 'truly', 'impressive', 'fisher', 'king', 'crap', 'complaint', 'brooks', 'cast', 'else', 'lead', 'love', 'mel', 'director', 'writer', 'lead']\n",
      "4 -----------\n",
      "['typical', 'mel', 'brooks', 'film', 'slapstick', 'movies', 'actually', 'plot', 'followable', 'leslie', 'ann', 'warren', 'movie', 'fantastic', 'underrated', 'actress', 'moments', 'fleshed', 'bit', 'scenes', 'probably', 'cut', 'worth', 'price', 'rent', 'acting', 'overall', 'brooks', 'job', 'characteristic', 'speaking', 'directly', 'audience', 'warren', 'actor', 'movie', 'fume', 'sailor', 'played']\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "****** testing data: ******\n",
      "0 -----------\n",
      "['story', 'unnatural', 'feelings', 'pig', 'starts', 'scene', 'terrific', 'example', 'absurd', 'comedy', 'formal', 'orchestra', 'audience', 'insane', 'violent', 'mob', 'crazy', 'chantings', 'singers', 'unfortunately', 'stays', 'absurd', 'time', 'narrative', 'eventually', 'putting', 'era', 'cryptic', 'dialogue', 'shakespeare', 'easy', 'third', 'grader', 'technical', 'level', 'cinematography', 'future', 'vilmos', 'zsigmond', 'future', 'stars', 'sally', 'kirkland', 'frederic', 'forrest', 'seen', 'briefly']\n",
      "1 -----------\n",
      "['airport', '77', 'starts', 'brand', 'luxury', '747', 'plane', 'loaded', 'valuable', 'paintings', 'belonging', 'rich', 'businessman', 'philip', 'stevens', 'james', 'stewart', 'flying', 'bunch', 'vips', 'estate', 'preparation', 'public', 'museum', 'board', 'stevens', 'daughter', 'julie', 'kathleen', 'quinlan', 'son', 'luxury', 'jetliner', 'takes', 'planned', 'midair', 'plane', 'hijacked', 'copilot', 'chambers', 'robert', 'foxworth', 'accomplices', 'banker', 'monte', 'markham', 'wilson', 'michael', 'pataki', 'knock', 'passengers', 'crew', 'sleeping', 'gas', 'plan', 'steal', 'valuable', 'cargo', 'land', 'disused', 'plane', 'strip', 'isolated', 'island', 'descent', 'chambers', 'hits', 'oil', 'rig', 'ocean', 'loses', 'control', 'plane', 'sending', 'crashing', 'sea', 'sinks', 'bottom', 'bang', 'middle', 'bermuda', 'triangle', 'air', 'short', 'supply', 'water', 'leaking', 'flown', '200', 'miles', 'course', 'mount', 'survivors', 'await', 'help', 'time', 'fast', 'running', 'slightly', 'tile', 'airport', '1977', 'sequel', 'smashhit', 'disaster', 'thriller', 'airport', '1970', 'directed', 'jerry', 'jameson', 'predecessors', 'cant', 'airport', '77', 'sort', 'forgotten', 'classic', 'entertaining', 'necessarily', 'reasons', 'airport', 'films', 'seen', 'actually', 'liked', 'favourite', 'plot', 'nice', 'midair', 'hijacking', 'crashing', 'didnt', 'oil', 'rig', 'sinking', '747', 'maybe', 'makers', 'trying', 'cross', 'original', 'airport', 'popular', 'disaster', 'flick', 'period', 'poseidon', 'adventure', '1972', 'submerged', 'stays', 'stark', 'dilemma', 'facing', 'trapped', 'inside', 'suffocate', 'air', 'runs', 'drown', '747', 'floods', 'doors', 'decent', 'idea', 'little', 'disaster', 'flick', 'bad', 'unsympathetic', 'characters', 'dull', 'dialogue', 'lethargic', 'setpieces', 'real', 'lack', 'danger', 'suspense', 'tension', 'means', 'missed', 'opportunity', 'sluggish', 'plot', 'entertained', '108', 'odd', 'minutes', 'happens', 'plane', 'sinks', 'theres', 'urgency', 'navy', 'involved', 'dont', 'pick', 'shots', 'huge', 'ships', 'helicopters', 'flying', 'theres', 'lacking', 'george', 'kennedy', 'jinxed', 'airline', 'worker', 'joe', 'patroni', 'couple', 'scenes', 'barely', 'preferring', 'look', 'worried', 'background', 'home', 'video', 'theatrical', 'version', 'airport', '77', 'run', '108', 'minutes', 'tv', 'versions', 'add', 'extra', 'hour', 'footage', 'including', 'credits', 'sequence', 'scenes', 'george', 'kennedy', 'patroni', 'flashbacks', 'flesh', 'characters', 'rescue', 'scenes', 'discovery', 'couple', 'dead', 'bodies', 'including', 'navigator', 'extra', 'footage', 'am', 'sit', 'near', 'hour', 'cut', 'airport', '77', 'expected', 'film', 'dated', 'badly', 'horrible', 'fashions', 'interior', 'design', 'choices', 'toy', 'plane', 'model', 'effects', 'arent', 'airport', 'sequels', 'takes', 'pride', 'razzie', 'awards', 'hall', 'shame', 'lots', 'worse', 'films', 'reckon', 'thats', 'little', 'harsh', 'action', 'scenes', 'little', 'dull', 'unfortunately', 'pace', 'slow', 'excitement', 'tension', 'generated', 'shame', 'reckon', 'pretty', 'film', 'properly', 'production', 'values', 'alright', 'spectacular', 'acting', 'isnt', 'time', 'oscar', 'winner', 'jack', 'lemmon', 'mistake', 'star', 'time', 'oscar', 'winner', 'james', 'stewart', 'looks', 'frail', 'time', 'oscar', 'winner', 'lee', 'grant', 'looks', 'drunk', 'sir', 'christopher', 'lee', 'little', 'plenty', 'familiar', 'look', 'airport', '77', 'disaster', 'orientated', 'airport', 'films', 'liked', 'ideas', 'bit', 'silly', 'production', 'bland', 'direction', 'doesnt', 'help', 'film', 'sunken', 'plane', 'shouldnt', 'boring', 'lethargic', 'followed', 'concorde', 'airport', '79', '1979']\n",
      "2 -----------\n",
      "['film', 'lacked', 'couldnt', 'finger', 'charisma', 'leading', 'actress', 'inevitably', 'translated', 'lack', 'chemistry', 'shared', 'screen', 'leading', 'romantic', 'scenes', 'merely', 'actors', 'play', 'director', 'miscalculated', 'actors', 'dont', 'screenplay', 'exactly', 'chef', 'love', 'enamored', 'culinary', 'skills', 'restaurant', 'ultimately', 'youthful', 'exploits', 'else', 'convinced', 'love', 'princess', 'disappointed', 'movie', 'dont', 'forget', 'nominated', 'oscar', 'judge', 'yourself']\n",
      "3 -----------\n",
      "['sorry', 'supposed', 'art', 'film', 'wow', 'handed', 'guns', 'screening', 'people', 'blow', 'brains', 'watch', 'scene', 'design', 'photographic', 'direction', 'excellent', 'story', 'painful', 'watch', 'absence', 'sound', 'track', 'brutal', 'loooonnnnng', 'shots', 'watch', 'people', 'sitting', 'talking', 'especially', 'dialogue', 'people', 'complaining', 'hard', 'time', 'getting', 'film', 'performances', 'excellent', 'dark', 'sombre', 'uninspired', 'stuff', 'liked', 'maureen', 'stapleton', 'red', 'dress', 'dancing', 'scene', 'otherwise', 'ripoff', 'bergman', 'im', 'fan', 'enjoyed', '1', '1', '2', 'hours', 'lying']\n",
      "4 -----------\n",
      "['little', 'parents', 'theater', 'interiors', 'movies', 'watched', 'parents', 'walked', 'seen', 'interiors', 'recently', 'lived', 'rest', 'life', 'pretentious', 'ponderous', 'painfully', 'boring', 'piece', '70s', 'wine', 'cheese', 'tripe', 'woody', 'allen', 'favorite', 'directors', 'interiors', 'worst', 'piece', 'crap', 'career', 'unmistakable', 'style', 'ingmar', 'berman', 'allen', 'dark', 'angular', 'muted', 'insight', 'lives', 'family', 'wrought', 'psychological', 'damage', 'caused', 'divorce', 'estrangement', 'career', 'love', 'nonlove', 'halitosis', 'whatever', 'film', 'intentionally', 'comic', 'relief', 'music', 'drenched', 'shadowy', 'pathos', 'film', 'style', 'defined', 'expressionist', 'nature', 'using', 'improvisational', 'method', 'dialogue', 'illicit', 'pronounced', 'depth', 'meaning', 'truth', 'woody', 'allen', 'ingmar', 'bergman', 'film', 'painfully', 'slow', 'dull', 'beyond', 'simply', 'connection', 'sympathy', 'characters', 'instead', 'contempt', 'parade', 'shuffling', 'whining', 'nicotine', 'stained', 'martyrs', 'perpetual', 'quest', 'identity', 'amid', 'backdrop', 'cosmopolitan', 'affluence', 'baked', 'brie', 'intelligentsia', 'story', 'looms', 'fart', 'speaks', 'affected', 'platitudes', 'elevated', 'language', 'cigarettes', 'lost', 'struggling', 'desperate', 'direction', 'understanding', 'whatever', 'goes', 'slap', 'resolution', 'interminable', 'introspective', 'babble', 'psychological', 'drama', 'extreme', 'beyond', 'audiences', 'ability', 'connect', 'woody', 'allen', 'chose', 'characters', 'immersed', 'themselves', 'feel', 'left', 'reason', 'found', 'movie', 'painfully', 'self', 'indulgent', 'spiritually', 'draining', 'insistence', 'promoting', 'message', 'prozac', 'prose', 'distorted', 'film', 'techniques', 'jettisons', 'past', 'relevance', 'highly', 'recommend', 'youre', 'feeling', 'little', 'happy', 'remind', 'death', 'otherwise', 'pretend', 'film', 'happened']\n",
      "\n",
      " neg ================> pos \n",
      "\n",
      "0 -----------\n",
      "['bromwell', 'cartoon', 'comedy', 'ran', 'time', 'programs', 'school', 'life', 'teachers', '35', 'teaching', 'profession', 'lead', 'believe', 'bromwell', 'highs', 'satire', 'closer', 'reality', 'teachers', 'scramble', 'survive', 'financially', 'insightful', 'students', 'pathetic', 'teachers', 'pomp', 'pettiness', 'situation', 'remind', 'schools', 'students', 'episode', 'student', 'repeatedly', 'tried', 'burn', 'school', 'immediately', 'recalled', 'classic', 'line', 'inspector', 'im', 'sack', 'teachers', 'student', 'welcome', 'bromwell', 'expect', 'adults', 'age', 'bromwell', 'fetched', 'pity', 'isnt']\n",
      "1 -----------\n",
      "['homelessness', 'houselessness', 'george', 'carlin', 'stated', 'issue', 'plan', 'help', 'street', 'considered', 'human', 'school', 'vote', 'matter', 'people', 'homeless', 'lost', 'cause', 'worrying', 'racism', 'war', 'iraq', 'pressuring', 'kids', 'succeed', 'technology', 'elections', 'inflation', 'worrying', 'theyll', 'streets', 'bet', 'live', 'streets', 'month', 'luxuries', 'home', 'entertainment', 'sets', 'bathroom', 'pictures', 'wall', 'computer', 'treasure', 'homeless', 'goddard', 'bolts', 'lesson', 'mel', 'brooks', 'directs', 'stars', 'bolt', 'plays', 'rich', 'world', 'deciding', 'bet', 'sissy', 'rival', 'jeffery', 'tambor', 'live', 'streets', 'thirty', 'days', 'luxuries', 'bolt', 'succeeds', 'future', 'project', 'buildings', 'bets', 'bolt', 'thrown', 'street', 'bracelet', 'leg', 'monitor', 'move', 'cant', 'step', 'sidewalk', 'hes', 'nickname', 'pepto', 'vagrant', 'written', 'forehead', 'bolt', 'meets', 'characters', 'including', 'woman', 'name', 'molly', 'lesley', 'ann', 'warren', 'exdancer', 'divorce', 'losing', 'home', 'pals', 'sailor', 'howard', 'morris', 'fumes', 'teddy', 'wilson', 'streets', 'theyre', 'survivors', 'bolt', 'isnt', 'hes', 'reaching', 'mutual', 'agreements', 'rich', 'fight', 'flight', 'kill', 'killed', 'love', 'connection', 'molly', 'bolt', 'wasnt', 'plot', 'found', 'life', 'stinks', 'mel', 'brooks', 'observant', 'films', 'prior', 'comedy', 'tender', 'compared', 'slapstick', 'blazing', 'saddles', 'frankenstein', 'spaceballs', 'matter', 'valuable', 'losing', 'day', 'hand', 'stupid', 'bet', 'rich', 'people', 'dont', 'money', 'maybe', 'homeless', 'instead', 'using', 'monopoly', 'money', 'maybe', 'film', 'inspire', 'help']\n",
      "2 -----------\n",
      "['brilliant', 'overacting', 'lesley', 'ann', 'warren', 'dramatic', 'hobo', 'lady', 'seen', 'love', 'scenes', 'clothes', 'warehouse', 'none', 'corn', 'classic', 'blazing', 'saddles', 'lawyers', 'superb', 'accused', 'turncoat', 'selling', 'boss', 'dishonest', 'lawyer', 'pepto', 'bolt', 'shrugs', 'indifferently', 'im', 'lawyer', 'funny', 'words', 'jeffrey', 'tambor', 'favorite', 'larry', 'sanders', 'fantastic', 'mad', 'millionaire', 'crush', 'ghetto', 'character', 'malevolent', 'usual', 'hospital', 'scene', 'scene', 'homeless', 'invade', 'demolition', 'site', 'alltime', 'classics', 'look', 'legs', 'scene', 'diggers', 'fighting', 'bleeds', 'movie', 'time']\n",
      "3 -----------\n",
      "['easily', 'underrated', 'film', 'inn', 'brooks', 'cannon', 'flawed', 'realistic', 'view', 'homelessness', 'unlike', 'citizen', 'kane', 'realistic', 'view', 'lounge', 'singers', 'titanic', 'realistic', 'view', 'italians', 'idiots', 'jokes', 'fall', 'flat', 'film', 'lovable', 'comedies', 'pull', 'story', 'traditionally', 'reviled', 'society', 'truly', 'impressive', 'fisher', 'king', 'crap', 'complaint', 'brooks', 'cast', 'else', 'lead', 'love', 'mel', 'director', 'writer', 'lead']\n",
      "4 -----------\n",
      "['typical', 'mel', 'brooks', 'film', 'slapstick', 'movies', 'actually', 'plot', 'followable', 'leslie', 'ann', 'warren', 'movie', 'fantastic', 'underrated', 'actress', 'moments', 'fleshed', 'bit', 'scenes', 'probably', 'cut', 'worth', 'price', 'rent', 'acting', 'overall', 'brooks', 'job', 'characteristic', 'speaking', 'directly', 'audience', 'warren', 'actor', 'movie', 'fume', 'sailor', 'played']\n"
     ]
    }
   ],
   "source": [
    "print '****** training data: ******'\n",
    "for i, tx in enumerate(X_train_list['neg'][0:5]):\n",
    "    print '%d -----------' % i\n",
    "    print tx\n",
    "       \n",
    "print '\\n neg ================> pos \\n'\n",
    "\n",
    "for i, tx in enumerate(X_train_list['pos'][0:5]):\n",
    "    print '%d -----------' % i\n",
    "    print tx\n",
    "\n",
    "print '\\n------------------------------------------\\n'\n",
    "\n",
    "print '****** testing data: ******'    \n",
    "for i, tx in enumerate(X_train_list['neg'][0:5]):\n",
    "    print '%d -----------' % i\n",
    "    print tx\n",
    "       \n",
    "print '\\n neg ================> pos \\n'\n",
    "\n",
    "for i, tx in enumerate(X_train_list['pos'][0:5]):\n",
    "    print '%d -----------' % i\n",
    "    print tx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vl = []\n",
    "for d in ['neg', 'pos']:\n",
    "    for doc in X_train_list[d]:\n",
    "        for wd in doc:\n",
    "            vl.append(wd)\n",
    "        \n",
    "voc_list = list(set(vl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95073"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voc_dict = {}\n",
    "for i, k in enumerate(voc_list):\n",
    "    voc_dict[k] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's very inefficient to use list of list to store data in Python. The below example shows how big difference they're. We need to use matrix as much as possible to improve our computation efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(25000 /1024) * (95073 / 1024) * 4 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array('i', [0, 5])\n"
     ]
    }
   ],
   "source": [
    "import array\n",
    "c = array.array(str(\"i\"))\n",
    "c.append(0)\n",
    "c.append(5)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of list implementation time cost: 0.000166654586792\n",
      "Matrix implementation time cost: 0.000666658083598\n"
     ]
    }
   ],
   "source": [
    "# Convert text to Bag of Words representation\n",
    "import scipy.sparse as sp\n",
    "import array\n",
    "\n",
    "def _make_int_array():\n",
    "    \"\"\"Construct an array.array of a type suitable for scipy.sparse indices.\"\"\"\n",
    "    return array.array(str(\"i\"))\n",
    "\n",
    "def frombuffer_empty(buf, dtype):\n",
    "        if len(buf) == 0:\n",
    "            return np.empty(0, dtype=dtype)\n",
    "        else:\n",
    "            return np.frombuffer(buf, dtype=dtype)\n",
    "        \n",
    "def doc2vec(doc_list, voc_list):\n",
    "    res_vec = {} # [0] * len(voc_list)\n",
    "    for word in doc_list:\n",
    "        if word in voc_list:\n",
    "            feature_indx = voc_dict[word]\n",
    "            if feature_indx in res_vec:\n",
    "                res_vec[feature_indx] += 1\n",
    "            else:\n",
    "                res_vec[feature_indx] = 1\n",
    "        \n",
    "    return res_vec\n",
    "\n",
    "def dataVectorization_origin(X, dataLabel, voc_list):\n",
    "    \"\"\"\n",
    "    dataBW = {}\n",
    "    for dl in dataLabel:\n",
    "        dataBW[dl] = []\n",
    "        for doc in X[dl]:\n",
    "            # dataBW[dl].append(doc2vec(doc, voc_list))\n",
    "            for word in doc:\n",
    "                if word in voc_list:\n",
    "                    try:\n",
    "                        feature_indx = voc_dict[word]\n",
    "                        if feature_indx in dataBW:\n",
    "                            dataBW[feature_indx] += 1\n",
    "                        else:\n",
    "                            dataBW[feature_indx] = 1\n",
    "                    except KeyError:\n",
    "                        # Ignore out-of-vocabulary items for fixed_vocab=True\n",
    "                        continue\n",
    "                        \n",
    "                    \n",
    "            \n",
    "    return dataBW\n",
    "    \n",
    "    \"\"\"    \n",
    "    j_indices = []\n",
    "    \n",
    "    # get efficient array 'array.array'.\n",
    "    indptr = _make_int_array()\n",
    "    values = _make_int_array()\n",
    "    \n",
    "    # The first pointer should point to the \n",
    "    # initial location, i.e. position 0.\n",
    "    #\n",
    "    # It's used to construct the parameter of\n",
    "    # 'csc_matrix((data, indices, indptr), [shape=(M, N)])'\n",
    "    indptr.append(0)\n",
    "    for dl in dataLabel:\n",
    "        for doc in X[dl]:\n",
    "            feature_counter = {}\n",
    "            for feature in doc:\n",
    "                try:\n",
    "                    feature_idx = voc_dict[feature]\n",
    "                    if not feature_idx in feature_counter:\n",
    "                        feature_counter[feature_idx] = 1\n",
    "                    else:\n",
    "                        feature_counter[feature_idx] += 1\n",
    "                except KeyError:\n",
    "                    # Ignore out-of-vocabulary items for fixed_vocab=True\n",
    "                    continue   \n",
    "            \n",
    "            # As array.array, it uses method 'extend'\n",
    "            # instead of 'append' to append element.\n",
    "            j_indices.extend(feature_counter.keys())\n",
    "            values.extend(feature_counter.values())\n",
    "            indptr.append(len(j_indices))\n",
    "            \n",
    "    \n",
    "    # Turn Python 'list' into numpy 'np.array'\n",
    "    j_indices = np.asarray(j_indices, dtype=np.intc)\n",
    "    # Turn Python 'array.array' into numpy 'np.array'\n",
    "    indptr = np.frombuffer(indptr, dtype=np.intc)\n",
    "    # Almost the same as above, except 'len(values) == 0' situation\n",
    "    values = frombuffer_empty(values, dtype=np.intc)\n",
    "\n",
    "    dataBW = sp.csr_matrix((values, j_indices, indptr),\n",
    "                      shape=(len(indptr) - 1, len(voc_dict)))\n",
    "\n",
    "    dataBW.sort_indices()\n",
    "    return dataBW\n",
    "\n",
    "def dataVectorization(X, voc_list):\n",
    "    num_pos = len(X['pos'])\n",
    "    num_neg = len(X['neg'])\n",
    "    \n",
    "    # For X_train_list:\n",
    "    #   - 25000 rows\n",
    "    #   - 95073 columns\n",
    "    #   - 4 bytes per element\n",
    "    # In all: 25000 * 95073 * 4 / (1024 ** 4) bytes, i.e. 8GB\n",
    "    # dataBW = sp.lil_matrix((num_pos + num_neg, len(voc_list)))\n",
    "    dataBW = np.zeros((num_pos + num_neg, len(voc_list)))\n",
    "    \n",
    "    for x in xrange(num_pos):\n",
    "        for doc in X['pos']:\n",
    "            for word in doc:\n",
    "                dataBW[x, voc_dict[word]] += 1\n",
    "                \n",
    "    for x in range(num_pos, num_pos + num_neg):\n",
    "        for doc in X['neg']:\n",
    "            for word in doc:\n",
    "                dataBW[x, voc_dict[word]] += 1\n",
    "            \n",
    "    return dataBW\n",
    "\n",
    "# print X_train['pos'][0]\n",
    "# print doc2vec(X_train['pos'][0], voc_list)\n",
    "# X_train = dataVectorization(X_train_list, dataLabel, voc_list)\n",
    "# print X_train['pos'][0]\n",
    "testData = {}\n",
    "testData['pos'] = X_train_list['pos'][0:5]\n",
    "testData['neg'] = X_train_list['neg'][0:5]\n",
    "import time \n",
    "\n",
    "tic = time.time()\n",
    "tt1 = dataVectorization_origin(testData, dataLabel, voc_list)\n",
    "tc = time.time()\n",
    "print 'List of list implementation time cost:', (tc - tic) / 6.0 \n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "tt = dataVectorization(testData, voc_list)\n",
    "tc = time.time()\n",
    "print 'Matrix implementation time cost:', (tc - tic) / 6.0 \n",
    "# print tt['neg'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.277774 min\n"
     ]
    }
   ],
   "source": [
    "totalTime = (len(X_train_list['pos']) + len(X_train_list['pos'])) * (tc - tic) / 6.0 \n",
    "print 'Total time: %f min' % (totalTime / 60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1610)\t1\n",
      "  (0, 1949)\t1\n",
      "  (0, 2326)\t1\n",
      "  (0, 8106)\t1\n",
      "  (0, 10303)\t1\n",
      "  (0, 12014)\t1\n",
      "  (0, 15867)\t1\n",
      "  (0, 17926)\t1\n",
      "  (0, 18048)\t1\n",
      "  (0, 18891)\t2\n",
      "  (0, 20882)\t4\n",
      "  (0, 23473)\t1\n",
      "  (0, 26896)\t1\n",
      "  (0, 26988)\t1\n",
      "  (0, 27610)\t4\n",
      "  (0, 28216)\t1\n",
      "  (0, 31568)\t1\n",
      "  (0, 32558)\t1\n",
      "  (0, 33619)\t1\n",
      "  (0, 36011)\t1\n",
      "  (0, 37539)\t1\n",
      "  (0, 38610)\t1\n",
      "  (0, 39008)\t1\n",
      "  (0, 39337)\t1\n",
      "  (0, 44637)\t1\n",
      "  :\t:\n",
      "  (24999, 47393)\t1\n",
      "  (24999, 48149)\t1\n",
      "  (24999, 49671)\t1\n",
      "  (24999, 50355)\t1\n",
      "  (24999, 50561)\t1\n",
      "  (24999, 61113)\t1\n",
      "  (24999, 61671)\t1\n",
      "  (24999, 61793)\t1\n",
      "  (24999, 63596)\t1\n",
      "  (24999, 64951)\t2\n",
      "  (24999, 67912)\t2\n",
      "  (24999, 68345)\t1\n",
      "  (24999, 69756)\t2\n",
      "  (24999, 71047)\t1\n",
      "  (24999, 74385)\t1\n",
      "  (24999, 76088)\t1\n",
      "  (24999, 77075)\t1\n",
      "  (24999, 77493)\t1\n",
      "  (24999, 78160)\t1\n",
      "  (24999, 78936)\t1\n",
      "  (24999, 80838)\t1\n",
      "  (24999, 84845)\t1\n",
      "  (24999, 85588)\t1\n",
      "  (24999, 90814)\t1\n",
      "  (24999, 91428)\t1\n"
     ]
    }
   ],
   "source": [
    "X_train1 = dataVectorization_origin(X_train_list, dataLabel, voc_list)\n",
    "print X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description\n",
      "DESCR\n",
      "filenames\n",
      "target_names\n",
      "data\n",
      "target\n"
     ]
    }
   ],
   "source": [
    "for k in twenty_train:\n",
    "    print k\n",
    "    # print \"(%s, %s)\\n\" % (k, twenty_train[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 3 3 3 3 3 2 2 2 3 1 0 0 1 1 2 0 3 0 3 0 3 1 1 1 3 3 2]\n"
     ]
    }
   ],
   "source": [
    "print twenty_train.target[0:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data)\n",
    "\n",
    "len(twenty_train.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888000011444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "tic = time.time()\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "print time.time() - tic\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Use IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.83599996567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25000, 74195)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "tic = time.time()\n",
    "cvect = CountVectorizer(analyzer=\"word\", stop_words=stop_words)\n",
    "X_train = cvect.fit_transform(IMDB_train['pos'] + IMDB_train['neg'])\n",
    "print time.time() - tic\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9176)\t4\n",
      "  (0, 10758)\t1\n",
      "  (0, 13383)\t1\n",
      "  (0, 52945)\t1\n",
      "  (0, 66361)\t1\n",
      "  (0, 51471)\t1\n",
      "  (0, 57539)\t2\n",
      "  (0, 38342)\t1\n",
      "  (0, 65201)\t4\n",
      "  (0, 641)\t1\n",
      "  (0, 65203)\t1\n",
      "  (0, 51412)\t1\n",
      "  (0, 37744)\t1\n",
      "  (0, 6653)\t1\n",
      "  (0, 57097)\t1\n",
      "  (0, 12827)\t1\n",
      "  (0, 53345)\t1\n",
      "  (0, 57727)\t1\n",
      "  (0, 64151)\t1\n",
      "  (0, 24430)\t1\n",
      "  (0, 33538)\t1\n",
      "  (0, 63241)\t2\n",
      "  (0, 48258)\t1\n",
      "  (0, 50295)\t1\n",
      "  (0, 49088)\t1\n",
      "  :\t:\n",
      "  (24999, 13660)\t1\n",
      "  (24999, 68226)\t2\n",
      "  (24999, 54182)\t1\n",
      "  (24999, 68818)\t1\n",
      "  (24999, 59866)\t1\n",
      "  (24999, 29859)\t1\n",
      "  (24999, 51389)\t1\n",
      "  (24999, 45532)\t1\n",
      "  (24999, 10118)\t1\n",
      "  (24999, 44749)\t1\n",
      "  (24999, 71639)\t1\n",
      "  (24999, 47619)\t1\n",
      "  (24999, 32316)\t1\n",
      "  (24999, 31216)\t1\n",
      "  (24999, 67135)\t1\n",
      "  (24999, 40241)\t1\n",
      "  (24999, 10369)\t1\n",
      "  (24999, 41998)\t2\n",
      "  (24999, 2124)\t1\n",
      "  (24999, 55466)\t1\n",
      "  (24999, 38780)\t1\n",
      "  (24999, 19727)\t1\n",
      "  (24999, 20261)\t1\n",
      "  (24999, 19731)\t1\n",
      "  (24999, 59182)\t1\n"
     ]
    }
   ],
   "source": [
    "print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "print len(([0] * len(IMDB_train['pos'])) + ([1] * len(IMDB_train['pos'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
